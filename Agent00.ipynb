{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcXkboxHwQjqNwA9mFnD2T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Cyber-Attack-Detection/blob/main/Agent00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJv7Ud6rnwu3",
        "outputId": "4c7f8790-2ec0-4945-9565-95ac1e89ac87"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53hTnhpznByx",
        "outputId": "5960a0b1-5322-49ea-91d5-1e397c794640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface-hub<1.0 in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install \"huggingface-hub<1.0\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "os.environ[\"HF_TOKEN\"] = getpass.getpass(\"Enter your token:\")"
      ],
      "metadata": {
        "id": "J-O9hVsTnIfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8936dff6-5a85-492c-a610-b907cf679fe4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your token:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TOKEN = os.environ[\"HF_TOKEN\"]"
      ],
      "metadata": {
        "id": "Z0U1jwi_mSx_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "client = InferenceClient(\n",
        "      api_key =HF_TOKEN,\n",
        "      model = \"moonshotai/Kimi-K2-Thinking\"\n",
        ")"
      ],
      "metadata": {
        "id": "IQTu7TRnlaBx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": \"What is the LLM+P?\"}\n",
        "        ]\n",
        ")"
      ],
      "metadata": {
        "id": "qgVscx01mVxx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.__dict__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg5WJ8XJozax",
        "outputId": "cda1ba38-c7a3-4a9e-a25f-cd0c93bc7b2e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'choices': [ChatCompletionOutputComplete(finish_reason='stop', index=0, message=ChatCompletionOutputMessage(role='assistant', content='**LLM+P** stands for **\"Large Language Model + Planning\"**, a framework that combines the natural language understanding capabilities of LLMs with external, domain-independent **classical planners** to solve complex planning tasks more reliably and optimally.\\n\\n## Core Idea\\n\\nWhile LLMs can generate reasonable-sounding plans from natural language descriptions, they often struggle with:\\n- Guaranteeing **optimality** (shortest/lowest-cost plans)\\n- Maintaining **logical consistency** in long-horizon tasks\\n- Handling complex constraints and dependencies\\n\\nLLM+P addresses this by leveraging LLMs for **language interpretation** and **formal translation**, while delegating the actual planning to specialized algorithms that guarantee correctness and optimality.\\n\\n## How It Works\\n\\nThe typical LLM+P pipeline involves:\\n\\n1. **Problem Interpretation**: An LLM reads a natural language description of a planning problem (e.g., \"Move boxes from room A to room C using a robot...\")\\n\\n2. **Formal Translation**: The LLM translates this into a formal planning language like **PDDL** (Planning Domain Definition Language), defining:\\n   - Objects (robot, boxes, rooms)\\n   - Initial state\\n   - Goal conditions\\n   - Actions with preconditions and effects\\n\\n3. **Optimal Planning**: A classical planner (e.g., Fast Downward, Optic) solves the PDDL problem, generating a provably optimal plan\\n\\n4. **Plan Execution/Translation**: The plan can be translated back to natural language or executed directly\\n\\n## Key Benefits\\n\\n| Aspect | Vanilla LLM Planning | LLM+P Framework |\\n|--------|---------------------|-----------------|\\n| **Optimality** | No guarantee | Guaranteed optimal solutions |\\n| **Scalability** | Degrades with complexity | Handles complex problems efficiently |\\n| **Correctness** | May hallucinate invalid actions | Provably correct plans |\\n| **Reliability** | Inconsistent across runs | Deterministic, reproducible results |\\n\\n## Example Application\\n\\n**Logistics Problem**: \"Deliver packages to locations X, Y, Z using trucks\"\\n- LLM translates this into PDDL with trucks, packages, locations, and fuel constraints\\n- Planner computes optimal route (e.g., minimizing fuel or time)\\n- Result is a provably optimal delivery sequence\\n\\n## Notable Implementation\\n\\nThe concept was formalized in the 2023 paper *\"LLM+P: Empowering Large Language Models with Optimal Planning Proficiency\"* by Liu et al. It demonstrates how even smaller LLMs can match or exceed the planning performance of much larger models when paired with external planners.\\n\\nThis approach exemplifies the **\"LLM as a translator/orchestrator\"** paradigm, where LLMs handle ambiguous natural language while specialized tools handle tasks requiring mathematical rigor.', reasoning=None, tool_call_id=None, tool_calls=None, reasoning_content='The user is asking about \"LLM+P\". I need to understand what this term means. \\n\\n\"LLM\" commonly stands for \"Large Language Model\". The \"+P\" is less standard. Let me think about what this could mean in the context of AI and language models.\\n\\nPossible interpretations of \"LLM+P\":\\n1. **LLM + Planning**: This seems most likely given recent research trends. There\\'s a paper titled \"LLM+P: Empowering Large Language Models with Optimal Planning Proficiency\" that specifically uses this notation. The idea is to combine LLMs with classical planners to solve planning problems more effectively.\\n2. **LLM + Prompting**: Could refer to advanced prompting techniques\\n3. **LLM + Programming**: Could refer to code generation or program synthesis\\n4. **LLM + Probing**: Less likely, but possible in an analysis context\\n5. **LLM + Privacy**: Could be about privacy-preserving methods\\n\\nGiven that \"LLM+P\" appears as a specific term in recent AI literature, the most accurate answer is likely about the **LLM+P framework** that combines Large Language Models with external planners. Let me recall the details of this approach.\\n\\nThe LLM+P framework was introduced to address the limitation that LLMs, while good at generating plans, may not always produce optimal or guaranteed correct plans for complex planning problems. The approach involves:\\n- Using the LLM to interpret natural language problem descriptions\\n- Translating them into a formal planning language (like PDDL - Planning Domain Definition Language)\\n- Using a classical planner to generate an optimal plan\\n- Translating the plan back to natural language if needed\\n\\nThis leverages the strengths of both: LLMs for language understanding and classical planners for optimal, verifiable planning.\\n\\nLet me structure a comprehensive answer:\\n1. Definition of LLM+P\\n2. The core idea and motivation\\n3. How it works (the process)\\n4. Key benefits\\n5. Examples/Applications\\n6. Contrast with vanilla LLM planning\\n7. References\\n\\nI should be clear and concise while providing enough technical detail.'), logprobs=None)],\n",
              " 'created': 1766382987,\n",
              " 'id': '0964b2eebcf8333be302fccdae732182',\n",
              " 'model': 'moonshotai/kimi-k2-thinking',\n",
              " 'system_fingerprint': '',\n",
              " 'usage': ChatCompletionOutputUsage(completion_tokens=989, prompt_tokens=14, total_tokens=1003, prompt_tokens_details=None, completion_tokens_details=None),\n",
              " 'object': 'chat.completion'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "uDbdviq6o3OK",
        "outputId": "d43a3b4a-cbc3-4209-f752-c830f48b75ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'**LLM+P** stands for **\"Large Language Model + Planning\"**, a framework that combines the natural language understanding capabilities of LLMs with external, domain-independent **classical planners** to solve complex planning tasks more reliably and optimally.\\n\\n## Core Idea\\n\\nWhile LLMs can generate reasonable-sounding plans from natural language descriptions, they often struggle with:\\n- Guaranteeing **optimality** (shortest/lowest-cost plans)\\n- Maintaining **logical consistency** in long-horizon tasks\\n- Handling complex constraints and dependencies\\n\\nLLM+P addresses this by leveraging LLMs for **language interpretation** and **formal translation**, while delegating the actual planning to specialized algorithms that guarantee correctness and optimality.\\n\\n## How It Works\\n\\nThe typical LLM+P pipeline involves:\\n\\n1. **Problem Interpretation**: An LLM reads a natural language description of a planning problem (e.g., \"Move boxes from room A to room C using a robot...\")\\n\\n2. **Formal Translation**: The LLM translates this into a formal planning language like **PDDL** (Planning Domain Definition Language), defining:\\n   - Objects (robot, boxes, rooms)\\n   - Initial state\\n   - Goal conditions\\n   - Actions with preconditions and effects\\n\\n3. **Optimal Planning**: A classical planner (e.g., Fast Downward, Optic) solves the PDDL problem, generating a provably optimal plan\\n\\n4. **Plan Execution/Translation**: The plan can be translated back to natural language or executed directly\\n\\n## Key Benefits\\n\\n| Aspect | Vanilla LLM Planning | LLM+P Framework |\\n|--------|---------------------|-----------------|\\n| **Optimality** | No guarantee | Guaranteed optimal solutions |\\n| **Scalability** | Degrades with complexity | Handles complex problems efficiently |\\n| **Correctness** | May hallucinate invalid actions | Provably correct plans |\\n| **Reliability** | Inconsistent across runs | Deterministic, reproducible results |\\n\\n## Example Application\\n\\n**Logistics Problem**: \"Deliver packages to locations X, Y, Z using trucks\"\\n- LLM translates this into PDDL with trucks, packages, locations, and fuel constraints\\n- Planner computes optimal route (e.g., minimizing fuel or time)\\n- Result is a provably optimal delivery sequence\\n\\n## Notable Implementation\\n\\nThe concept was formalized in the 2023 paper *\"LLM+P: Empowering Large Language Models with Optimal Planning Proficiency\"* by Liu et al. It demonstrates how even smaller LLMs can match or exceed the planning performance of much larger models when paired with external planners.\\n\\nThis approach exemplifies the **\"LLM as a translator/orchestrator\"** paradigm, where LLMs handle ambiguous natural language while specialized tools handle tasks requiring mathematical rigor.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEFuR2gA613q",
        "outputId": "e0d7cd7b-ad9c-4d1a-f602-0a5301fdd64f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**LLM+P** stands for **\"Large Language Model + Planning\"**, a framework that combines the natural language understanding capabilities of LLMs with external, domain-independent **classical planners** to solve complex planning tasks more reliably and optimally.\n",
            "\n",
            "## Core Idea\n",
            "\n",
            "While LLMs can generate reasonable-sounding plans from natural language descriptions, they often struggle with:\n",
            "- Guaranteeing **optimality** (shortest/lowest-cost plans)\n",
            "- Maintaining **logical consistency** in long-horizon tasks\n",
            "- Handling complex constraints and dependencies\n",
            "\n",
            "LLM+P addresses this by leveraging LLMs for **language interpretation** and **formal translation**, while delegating the actual planning to specialized algorithms that guarantee correctness and optimality.\n",
            "\n",
            "## How It Works\n",
            "\n",
            "The typical LLM+P pipeline involves:\n",
            "\n",
            "1. **Problem Interpretation**: An LLM reads a natural language description of a planning problem (e.g., \"Move boxes from room A to room C using a robot...\")\n",
            "\n",
            "2. **Formal Translation**: The LLM translates this into a formal planning language like **PDDL** (Planning Domain Definition Language), defining:\n",
            "   - Objects (robot, boxes, rooms)\n",
            "   - Initial state\n",
            "   - Goal conditions\n",
            "   - Actions with preconditions and effects\n",
            "\n",
            "3. **Optimal Planning**: A classical planner (e.g., Fast Downward, Optic) solves the PDDL problem, generating a provably optimal plan\n",
            "\n",
            "4. **Plan Execution/Translation**: The plan can be translated back to natural language or executed directly\n",
            "\n",
            "## Key Benefits\n",
            "\n",
            "| Aspect | Vanilla LLM Planning | LLM+P Framework |\n",
            "|--------|---------------------|-----------------|\n",
            "| **Optimality** | No guarantee | Guaranteed optimal solutions |\n",
            "| **Scalability** | Degrades with complexity | Handles complex problems efficiently |\n",
            "| **Correctness** | May hallucinate invalid actions | Provably correct plans |\n",
            "| **Reliability** | Inconsistent across runs | Deterministic, reproducible results |\n",
            "\n",
            "## Example Application\n",
            "\n",
            "**Logistics Problem**: \"Deliver packages to locations X, Y, Z using trucks\"\n",
            "- LLM translates this into PDDL with trucks, packages, locations, and fuel constraints\n",
            "- Planner computes optimal route (e.g., minimizing fuel or time)\n",
            "- Result is a provably optimal delivery sequence\n",
            "\n",
            "## Notable Implementation\n",
            "\n",
            "The concept was formalized in the 2023 paper *\"LLM+P: Empowering Large Language Models with Optimal Planning Proficiency\"* by Liu et al. It demonstrates how even smaller LLMs can match or exceed the planning performance of much larger models when paired with external planners.\n",
            "\n",
            "This approach exemplifies the **\"LLM as a translator/orchestrator\"** paradigm, where LLMs handle ambiguous natural language while specialized tools handle tasks requiring mathematical rigor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "pprint.pprint(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lwqMk1i6-XZ",
        "outputId": "72bf39fd-e75d-4533-a536-fcd8efa46c2c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('**LLM+P** stands for **\"Large Language Model + Planning\"**, a framework that '\n",
            " 'combines the natural language understanding capabilities of LLMs with '\n",
            " 'external, domain-independent **classical planners** to solve complex '\n",
            " 'planning tasks more reliably and optimally.\\n'\n",
            " '\\n'\n",
            " '## Core Idea\\n'\n",
            " '\\n'\n",
            " 'While LLMs can generate reasonable-sounding plans from natural language '\n",
            " 'descriptions, they often struggle with:\\n'\n",
            " '- Guaranteeing **optimality** (shortest/lowest-cost plans)\\n'\n",
            " '- Maintaining **logical consistency** in long-horizon tasks\\n'\n",
            " '- Handling complex constraints and dependencies\\n'\n",
            " '\\n'\n",
            " 'LLM+P addresses this by leveraging LLMs for **language interpretation** and '\n",
            " '**formal translation**, while delegating the actual planning to specialized '\n",
            " 'algorithms that guarantee correctness and optimality.\\n'\n",
            " '\\n'\n",
            " '## How It Works\\n'\n",
            " '\\n'\n",
            " 'The typical LLM+P pipeline involves:\\n'\n",
            " '\\n'\n",
            " '1. **Problem Interpretation**: An LLM reads a natural language description '\n",
            " 'of a planning problem (e.g., \"Move boxes from room A to room C using a '\n",
            " 'robot...\")\\n'\n",
            " '\\n'\n",
            " '2. **Formal Translation**: The LLM translates this into a formal planning '\n",
            " 'language like **PDDL** (Planning Domain Definition Language), defining:\\n'\n",
            " '   - Objects (robot, boxes, rooms)\\n'\n",
            " '   - Initial state\\n'\n",
            " '   - Goal conditions\\n'\n",
            " '   - Actions with preconditions and effects\\n'\n",
            " '\\n'\n",
            " '3. **Optimal Planning**: A classical planner (e.g., Fast Downward, Optic) '\n",
            " 'solves the PDDL problem, generating a provably optimal plan\\n'\n",
            " '\\n'\n",
            " '4. **Plan Execution/Translation**: The plan can be translated back to '\n",
            " 'natural language or executed directly\\n'\n",
            " '\\n'\n",
            " '## Key Benefits\\n'\n",
            " '\\n'\n",
            " '| Aspect | Vanilla LLM Planning | LLM+P Framework |\\n'\n",
            " '|--------|---------------------|-----------------|\\n'\n",
            " '| **Optimality** | No guarantee | Guaranteed optimal solutions |\\n'\n",
            " '| **Scalability** | Degrades with complexity | Handles complex problems '\n",
            " 'efficiently |\\n'\n",
            " '| **Correctness** | May hallucinate invalid actions | Provably correct plans '\n",
            " '|\\n'\n",
            " '| **Reliability** | Inconsistent across runs | Deterministic, reproducible '\n",
            " 'results |\\n'\n",
            " '\\n'\n",
            " '## Example Application\\n'\n",
            " '\\n'\n",
            " '**Logistics Problem**: \"Deliver packages to locations X, Y, Z using trucks\"\\n'\n",
            " '- LLM translates this into PDDL with trucks, packages, locations, and fuel '\n",
            " 'constraints\\n'\n",
            " '- Planner computes optimal route (e.g., minimizing fuel or time)\\n'\n",
            " '- Result is a provably optimal delivery sequence\\n'\n",
            " '\\n'\n",
            " '## Notable Implementation\\n'\n",
            " '\\n'\n",
            " 'The concept was formalized in the 2023 paper *\"LLM+P: Empowering Large '\n",
            " 'Language Models with Optimal Planning Proficiency\"* by Liu et al. It '\n",
            " 'demonstrates how even smaller LLMs can match or exceed the planning '\n",
            " 'performance of much larger models when paired with external planners.\\n'\n",
            " '\\n'\n",
            " 'This approach exemplifies the **\"LLM as a translator/orchestrator\"** '\n",
            " 'paradigm, where LLMs handle ambiguous natural language while specialized '\n",
            " 'tools handle tasks requiring mathematical rigor.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "pprint.pprint(response.choices[0].message.reasoning_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXTFPowy7bvh",
        "outputId": "e7e3a71d-304f-41df-ea54-ad47a0b8da13"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('The user is asking about \"LLM+P\". I need to understand what this term '\n",
            " 'means. \\n'\n",
            " '\\n'\n",
            " '\"LLM\" commonly stands for \"Large Language Model\". The \"+P\" is less standard. '\n",
            " 'Let me think about what this could mean in the context of AI and language '\n",
            " 'models.\\n'\n",
            " '\\n'\n",
            " 'Possible interpretations of \"LLM+P\":\\n'\n",
            " '1. **LLM + Planning**: This seems most likely given recent research trends. '\n",
            " 'There\\'s a paper titled \"LLM+P: Empowering Large Language Models with '\n",
            " 'Optimal Planning Proficiency\" that specifically uses this notation. The idea '\n",
            " 'is to combine LLMs with classical planners to solve planning problems more '\n",
            " 'effectively.\\n'\n",
            " '2. **LLM + Prompting**: Could refer to advanced prompting techniques\\n'\n",
            " '3. **LLM + Programming**: Could refer to code generation or program '\n",
            " 'synthesis\\n'\n",
            " '4. **LLM + Probing**: Less likely, but possible in an analysis context\\n'\n",
            " '5. **LLM + Privacy**: Could be about privacy-preserving methods\\n'\n",
            " '\\n'\n",
            " 'Given that \"LLM+P\" appears as a specific term in recent AI literature, the '\n",
            " 'most accurate answer is likely about the **LLM+P framework** that combines '\n",
            " 'Large Language Models with external planners. Let me recall the details of '\n",
            " 'this approach.\\n'\n",
            " '\\n'\n",
            " 'The LLM+P framework was introduced to address the limitation that LLMs, '\n",
            " 'while good at generating plans, may not always produce optimal or guaranteed '\n",
            " 'correct plans for complex planning problems. The approach involves:\\n'\n",
            " '- Using the LLM to interpret natural language problem descriptions\\n'\n",
            " '- Translating them into a formal planning language (like PDDL - Planning '\n",
            " 'Domain Definition Language)\\n'\n",
            " '- Using a classical planner to generate an optimal plan\\n'\n",
            " '- Translating the plan back to natural language if needed\\n'\n",
            " '\\n'\n",
            " 'This leverages the strengths of both: LLMs for language understanding and '\n",
            " 'classical planners for optimal, verifiable planning.\\n'\n",
            " '\\n'\n",
            " 'Let me structure a comprehensive answer:\\n'\n",
            " '1. Definition of LLM+P\\n'\n",
            " '2. The core idea and motivation\\n'\n",
            " '3. How it works (the process)\\n'\n",
            " '4. Key benefits\\n'\n",
            " '5. Examples/Applications\\n'\n",
            " '6. Contrast with vanilla LLM planning\\n'\n",
            " '7. References\\n'\n",
            " '\\n'\n",
            " 'I should be clear and concise while providing enough technical detail.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_temp(city: str):\n",
        "  if city.lower() == \"tehran\":\n",
        "    return '40'\n",
        "  if city.lower() == \"istanbul\":\n",
        "    return '30'\n",
        "  return '20'"
      ],
      "metadata": {
        "id": "QixjkH3T8us0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_temp_tool_schema = {\n",
        "    \"type\" : \"function\",\n",
        "    \"function\" : {\n",
        "        \"name\" : \"get_temp\",\n",
        "        \"description\" : \"Get the temperature in a city\",\n",
        "        \"parameters\" : {\n",
        "            \"type\" : \"object\",\n",
        "            \"properties\" : {\n",
        "                \"city\" : {\n",
        "                    \"type\" : \"string\",\n",
        "                    \"description\" : \"The city to get the temperature for\"\n",
        "                }\n",
        "            },\n",
        "            \"required\" : [\"city\"]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "XGqoKZRZ-iSX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "class GetTempArgs(BaseModel):\n",
        "  city: str = Field(..., description=\"The city to get the temperature for\")"
      ],
      "metadata": {
        "id": "T1aMH3lnFe8k"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}