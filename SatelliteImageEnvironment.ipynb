{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5VRDBY0Wv5a39xCOm8cwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Cyber-Attack-Detection/blob/main/SatelliteImageEnvironment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vegetation Monitoring with Sentinel-2 RGB Dataset Using Classical Computer Vision\n",
        "\n",
        "## Project Overview\n",
        "Develop a vegetation monitoring system using the Sentinel-2 RGB captioned dataset with classical computer vision techniques to analyze vegetation cover, health, and changes over time.\n",
        "\n",
        "## Dataset Information\n",
        "**Dataset**: `sshh12/sentinel-2-rgb-captioned` from Hugging Face\n",
        "- **Content**: Pre-processed Sentinel-2 RGB images with captions\n",
        "- **Format**: RGB images (Red, Green, Blue bands)\n",
        "- **Advantages**: Clean, pre-processed data with descriptive captions\n",
        "- **Focus**: Vegetation analysis using visible spectrum\n",
        "\n",
        "## Detailed Workflow\n",
        "\n",
        "### Phase 1: Dataset Setup & Exploration ( 1)\n",
        "**Objectives:**\n",
        "- Load and explore the Sentinel-2 RGB dataset\n",
        "- Understand data structure and captions\n",
        "- Set up vegetation monitoring framework\n",
        "\n",
        "**Tasks:**\n",
        "1. **Dataset Loading**\n",
        "   ```python\n",
        "   from datasets import load_dataset\n",
        "   ds = load_dataset(\"sshh12/sentinel-2-rgb-captioned\")\n",
        "   ```\n",
        "2. **Data Exploration**\n",
        "   - Analyze image dimensions and RGB channel distributions\n",
        "   - Study caption content for vegetation-related keywords\n",
        "   - Create sample visualizations of different vegetation types\n",
        "3. **Environment Setup**\n",
        "   - Install libraries: OpenCV, scikit-image, matplotlib, pandas, numpy\n",
        "   - Set up project structure for vegetation analysis\n",
        "\n",
        "### Phase 2: Vegetation-Focused Preprocessing ( 2)\n",
        "**Objectives:**\n",
        "- Enhance RGB images for vegetation analysis\n",
        "- Extract vegetation-specific features from limited spectral bands\n",
        "\n",
        "**Classical CV Techniques:**\n",
        "1. **RGB Enhancement for Vegetation**\n",
        "   - Histogram equalization on individual channels\n",
        "   - Contrast Limited Adaptive Histogram Equalization (CLAHE)\n",
        "   - Color space conversions (RGB → HSV, RGB → LAB)\n",
        "\n",
        "2. **Vegetation Index Approximation**\n",
        "   - **Visible Atmospherically Resistant Index (VARI)**: (Green - Red) / (Green + Red - Blue)\n",
        "   - **Green Leaf Index (GLI)**: (2×Green - Red - Blue) / (2×Green + Red + Blue)\n",
        "   - **Red-Green Ratio**: Red/Green for vegetation stress detection\n",
        "\n",
        "3. **Color-Based Vegetation Enhancement**\n",
        "   - Green channel enhancement\n",
        "   - Color thresholding for vegetation masking\n",
        "   - HSV-based vegetation extraction\n",
        "\n",
        "### Phase 3: Vegetation Feature Extraction ( 3)\n",
        "**Objectives:**\n",
        "- Extract vegetation-specific features from RGB imagery\n",
        "\n",
        "**Classical CV Techniques:**\n",
        "1. **Color-Based Vegetation Features**\n",
        "   - **Green Dominance Analysis**: Quantify green pixel distribution\n",
        "   - **Color Moment Analysis**: Mean, variance, skewness of each channel\n",
        "   - **Color Histogram Features**: Vegetation-specific color patterns\n",
        "\n",
        "2. **Texture Analysis for Vegetation**\n",
        "   - **GLCM on Green Channel**: Vegetation texture characterization\n",
        "   - **Local Binary Patterns (LBP)**: Forest vs. grassland texture differentiation\n",
        "   - **Gabor Filters**: Directional texture analysis for crop patterns\n",
        "\n",
        "3. **Morphological Features**\n",
        "   - **Vegetation Boundary Detection**: Canny edge detection on green-enhanced images\n",
        "   - **Shape Analysis**: Contour analysis for vegetation patches\n",
        "   - **Canopy Structure**: Morphological operations to identify tree crowns\n",
        "\n",
        "4. **Spatial Vegetation Patterns**\n",
        "   - **Vegetation Density Maps**: Green pixel density analysis\n",
        "   - **Patch Size Distribution**: Connected component analysis\n",
        "   - **Fragmentation Metrics**: Edge-to-area ratios\n",
        "\n",
        "### Phase 4: Vegetation Classification & Segmentation ( 4)\n",
        "**Objectives:**\n",
        "- Classify different vegetation types and health conditions\n",
        "\n",
        "**Vegetation Categories:**\n",
        "- Dense Forest\n",
        "- Sparse Forest/Woodland\n",
        "- Grassland/Shrubland\n",
        "- Agricultural Crops\n",
        "- Stressed/Unhealthy Vegetation\n",
        "- Non-Vegetation (Urban, Water, Bare Soil)\n",
        "\n",
        "**Classical CV Techniques:**\n",
        "1. **Color-Based Segmentation**\n",
        "   - **K-means Clustering**: Separate vegetation types by color characteristics\n",
        "   - **HSV Thresholding**: Isolate healthy green vegetation\n",
        "   - **Watershed Segmentation**: Separate individual vegetation patches\n",
        "\n",
        "2. **Machine Learning Classification**\n",
        "   - **Support Vector Machine (SVM)**: Multi-class vegetation classification\n",
        "   - **Random Forest**: Combine multiple vegetation features\n",
        "   - **Decision Trees**: Interpretable vegetation health assessment\n",
        "\n",
        "3. **Rule-Based Classification**\n",
        "   - **Vegetation Index Thresholding**: VARI and GLI-based classification\n",
        "   - **Color Rule Sets**: IF-THEN rules for vegetation types\n",
        "   - **Multi-criteria Decision**: Combine color, texture, and shape features\n",
        "\n",
        "### Phase 5: Vegetation Health Assessment ( 5)\n",
        "**Objectives:**\n",
        "- Assess vegetation health and stress conditions\n",
        "\n",
        "**Classical CV Approaches:**\n",
        "1. **Health Indicators from RGB**\n",
        "   - **Greenness Assessment**: Green channel intensity analysis\n",
        "   - **Color Deviation Analysis**: Deviation from healthy vegetation colors\n",
        "   - **Browning Detection**: Red/Brown pixel identification for stress\n",
        "\n",
        "2. **Vegetation Vigor Analysis**\n",
        "   - **VARI Trend Analysis**: Vegetation activity and vigor\n",
        "   - **Seasonal Color Changes**: Multi-temporal color analysis\n",
        "   - **Stress Pattern Recognition**: Identify yellowing/browning patterns\n",
        "\n",
        "3. **Canopy Analysis**\n",
        "   - **Canopy Coverage**: Percentage of vegetation cover\n",
        "   - **Canopy Density**: Pixel intensity-based density estimation\n",
        "   - **Gap Analysis**: Identify clearings and deforestation\n",
        "\n",
        "### Phase 6: Temporal Vegetation Analysis ( 6)\n",
        "**Objectives:**\n",
        "- Monitor vegetation changes over time using available temporal data\n",
        "\n",
        "**Change Detection Methods:**\n",
        "1. **RGB-Based Change Detection**\n",
        "   - **Image Differencing**: Compare vegetation indices across time\n",
        "   - **Color Change Analysis**: Track color shifts indicating phenology\n",
        "   - **Threshold-Based Change**: Binary change detection\n",
        "\n",
        "2. **Vegetation Trend Analysis**\n",
        "   - **Greenness Trends**: Long-term vegetation health trends\n",
        "   - **Seasonal Pattern Recognition**: Identify phenological cycles\n",
        "   - **Disturbance Detection**: Identify sudden vegetation loss\n",
        "\n",
        "### Phase 7: Validation & Results ( 7)\n",
        "**Objectives:**\n",
        "- Validate results and create comprehensive vegetation analysis\n",
        "\n",
        "**Validation Methods:**\n",
        "1. **Caption-Based Validation**\n",
        "   - Use image captions to validate classification results\n",
        "   - Cross-reference vegetation descriptions with analysis\n",
        "   - Accuracy assessment using caption keywords\n",
        "\n",
        "2. **Visual Validation**\n",
        "   - Expert interpretation of results\n",
        "   - Comparison with known vegetation patterns\n",
        "   - Ground truth validation where available\n",
        "\n",
        "## Technical Implementation Stack\n",
        "\n",
        "### Core Libraries\n",
        "```python\n",
        "# Data handling\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Image processing\n",
        "import cv2\n",
        "from skimage import filters, segmentation, measure, morphology\n",
        "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "```\n",
        "\n",
        "### Key Vegetation Algorithms\n",
        "1. **VARI Calculation**: `(Green - Red) / (Green + Red - Blue)`\n",
        "2. **GLI Calculation**: `(2*Green - Red - Blue) / (2*Green + Red + Blue)`\n",
        "3. **Green Dominance**: `Green / (Red + Green + Blue)`\n",
        "4. **Vegetation Masking**: HSV-based green extraction\n",
        "5. **Canopy Coverage**: Green pixel percentage calculation\n",
        "\n",
        "## Vegetation-Specific Features to Extract\n",
        "\n",
        "### Color Features\n",
        "- Mean, std, skewness of R, G, B channels\n",
        "- VARI and GLI vegetation indices\n",
        "- Green dominance ratio\n",
        "- HSV color moments\n",
        "- Color histogram bins\n",
        "\n",
        "### Texture Features\n",
        "- GLCM properties (contrast, dissimilarity, homogeneity, energy)\n",
        "- LBP histogram for vegetation texture\n",
        "- Gabor filter responses for directional patterns\n",
        "\n",
        "### Morphological Features\n",
        "- Vegetation patch area and perimeter\n",
        "- Compactness and roundness of vegetation areas\n",
        "- Edge density within vegetation regions\n",
        "\n",
        "## Expected Vegetation Classification Results\n",
        "\n",
        "### Vegetation Types to Identify\n",
        "1. **Dense Forest**: High green intensity, coarse texture\n",
        "2. **Open Woodland**: Moderate green, mixed texture\n",
        "3. **Grassland**: Uniform green, fine texture\n",
        "4. **Cropland**: Regular patterns, seasonal color changes\n",
        "5. **Stressed Vegetation**: Yellow/brown tones, reduced green intensity\n",
        "6. **Mixed Vegetation**: Varied color and texture patterns\n",
        "\n",
        "### Performance Metrics\n",
        "- Overall classification accuracy > 80%\n",
        "- Vegetation vs. non-vegetation accuracy > 90%\n",
        "- Healthy vs. stressed vegetation accuracy > 75%\n",
        "- F1-score per vegetation class > 0.7\n",
        "\n",
        "## Sample Code Structure\n",
        "\n",
        "```python\n",
        "# 1. Dataset loading and exploration\n",
        "ds = load_dataset(\"sshh12/sentinel-2-rgb-captioned\")\n",
        "explore_vegetation_dataset(ds)\n",
        "\n",
        "# 2. Preprocessing\n",
        "enhanced_images = preprocess_for_vegetation(ds['image'])\n",
        "vegetation_indices = calculate_vegetation_indices(enhanced_images)\n",
        "\n",
        "# 3. Feature extraction\n",
        "color_features = extract_color_features(enhanced_images)\n",
        "texture_features = extract_texture_features(enhanced_images)\n",
        "vegetation_features = combine_features(color_features, texture_features, vegetation_indices)\n",
        "\n",
        "# 4. Classification\n",
        "vegetation_classifier = train_vegetation_classifier(vegetation_features, labels)\n",
        "vegetation_map = classify_vegetation(test_images)\n",
        "\n",
        "# 5. Analysis and visualization\n",
        "analyze_vegetation_health(vegetation_map)\n",
        "create_vegetation_visualizations(results)\n",
        "```\n",
        "\n",
        "## Final Deliverables\n",
        "1. **Vegetation Classification System**: Automated vegetation type identification\n",
        "2. **Vegetation Health Assessment Tool**: RGB-based health monitoring\n",
        "3. **Vegetation Coverage Analysis**: Quantitative vegetation coverage metrics\n",
        "4. **Temporal Vegetation Monitoring**: Change detection capabilities\n",
        "5. **Comprehensive Report**: Methodology, results, and vegetation insights\n",
        "6. **Interactive Visualizations**: Vegetation maps and health indicators\n",
        "\n",
        "## Success Criteria\n",
        "- Accurate vegetation type classification using only RGB data\n",
        "- Effective vegetation health assessment from color analysis\n",
        "- Reliable vegetation change detection over time\n",
        "- Clear visualization of vegetation patterns and trends\n",
        "- Validation against image captions and expert knowledge"
      ],
      "metadata": {
        "id": "ZIfdUAI94vMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's install required packages\n",
        "!pip install mlcroissant datasets matplotlib pandas plotly pillow\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import io\n",
        "import requests\n",
        "from datasets import load_dataset\n",
        "from plotly import express as px\n",
        "\n",
        "# Since mlcroissant gave warnings, let's try loading the dataset directly via Hugging Face datasets\n",
        "# This is often more reliable for image datasets\n",
        "dataset = load_dataset(\"sshh12/sentinel-2-rgb-captioned\")\n",
        "\n",
        "# Let's explore the dataset structure\n",
        "print(\"\\nDataset structure:\")\n",
        "print(dataset)\n",
        "\n",
        "# Let's create a pandas DataFrame for analysis\n",
        "def create_dataframe(dataset, split='train', sample_size=None):\n",
        "    data = dataset[split]\n",
        "    if sample_size:\n",
        "        data = data.select(range(sample_size))\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "# Create a DataFrame with 10 samples\n",
        "df = create_dataframe(dataset, 'train', 10)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "display(df.head())\n",
        "\n",
        "# Function to display images with captions\n",
        "def display_images_with_captions(df):\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    for i, (image, caption) in enumerate(zip(df['image'], df['caption'])):\n",
        "        plt.subplot(2, 5, i+1)\n",
        "        plt.imshow(image)\n",
        "        plt.title(caption[:50] + \"...\" if len(caption) > 50 else caption, fontsize=8)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display 10 images with their captions\n",
        "print(\"\\nDisplaying 10 images with captions:\")\n",
        "display_images_with_captions(df)\n",
        "\n",
        "# Analyze the captions\n",
        "print(\"\\nCaption length analysis:\")\n",
        "df['caption_length'] = df['caption'].apply(len)\n",
        "\n",
        "# Create a histogram of caption lengths\n",
        "fig = px.histogram(df, x='caption_length',\n",
        "                   title='Distribution of Caption Lengths',\n",
        "                   labels={'caption_length': 'Caption Length (characters)'})\n",
        "fig.show()\n",
        "\n",
        "# Show basic statistics\n",
        "print(\"\\nBasic statistics about the dataset:\")\n",
        "print(df['caption_length'].describe())\n",
        "\n",
        "# If you want to see the full caption for any image\n",
        "print(\"\\nFull captions for the displayed images:\")\n",
        "for i, caption in enumerate(df['caption']):\n",
        "    print(f\"\\nImage {i+1} caption: {caption}\")\n",
        "\n",
        "# If you want to see more metadata about the dataset\n",
        "print(\"\\nDataset features:\")\n",
        "print(dataset['train'].features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHnG3m5PI6rH",
        "outputId": "8d48659b-e38a-40aa-a588-1196b6008298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlcroissant\n",
            "  Downloading mlcroissant-1.0.17-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (1.4.0)\n",
            "Requirement already satisfied: etils>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.7.0->mlcroissant) (1.12.2)\n",
            "Collecting jsonpath-rw (from mlcroissant)\n",
            "  Downloading jsonpath-rw-1.4.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (3.5)\n",
            "Requirement already satisfied: pandas-stubs in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (2.2.2.240909)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (2.9.0.post0)\n",
            "Collecting rdflib (from mlcroissant)\n",
            "  Downloading rdflib-7.1.4-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (2.32.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (1.15.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.7.0->mlcroissant) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.7.0->mlcroissant) (4.14.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.7.0->mlcroissant) (3.22.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->mlcroissant) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->mlcroissant) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->mlcroissant) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->mlcroissant) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->mlcroissant) (2025.4.26)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.11/dist-packages (from jsonpath-rw->mlcroissant) (3.11)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from jsonpath-rw->mlcroissant) (4.4.2)\n",
            "Requirement already satisfied: types-pytz>=2022.1.1 in /usr/local/lib/python3.11/dist-packages (from pandas-stubs->mlcroissant) (2025.2.0.20250516)\n",
            "Downloading mlcroissant-1.0.17-py2.py3-none-any.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.4/141.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdflib-7.1.4-py3-none-any.whl (565 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.1/565.1 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: jsonpath-rw\n",
            "  Building wheel for jsonpath-rw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonpath-rw: filename=jsonpath_rw-1.4.0-py3-none-any.whl size=15127 sha256=c17ff7fb9ca06ac7284ec8c0b1d86657f5e845e31a43f61fa99db0edb914b45e\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/cf/51/a4ea10224b7fdb523e18e2033cadf2a8657517d1f95f3f5413\n",
            "Successfully built jsonpath-rw\n",
            "Installing collected packages: rdflib, jsonpath-rw, mlcroissant\n",
            "Successfully installed jsonpath-rw-1.4.0 mlcroissant-1.0.17 rdflib-7.1.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}