{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMCeaouiU20aHASQyaxxDPk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "063f5db9ea5449b89be540f6545f4fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5faccd02f3284d929349b4df686672f7",
              "IPY_MODEL_ff06aa9d6c1e4ae28556c2f0873be096",
              "IPY_MODEL_8cfdd7d4c956467e944ef99b72142a3f"
            ],
            "layout": "IPY_MODEL_8c0918fb5fec4a9cac47a10964a1f13a"
          }
        },
        "5faccd02f3284d929349b4df686672f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63ba1bcdc8c6425ea95b3168a3a5c64d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e01c196bcd9c4830a96dba987d6d6795",
            "value": "Downloading‚Äáreadme:‚Äá100%"
          }
        },
        "ff06aa9d6c1e4ae28556c2f0873be096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6650ae0c2e4f4e94b2abb9fcacfdc548",
            "max": 880,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60dbb88940c1485bb97a58a6cfa2bc99",
            "value": 880
          }
        },
        "8cfdd7d4c956467e944ef99b72142a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c96fe3fc9545348e088118769dd269",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c3d1cbc84fc949ae811298afa4f88a6e",
            "value": "‚Äá880/880‚Äá[00:00&lt;00:00,‚Äá81.3kB/s]"
          }
        },
        "8c0918fb5fec4a9cac47a10964a1f13a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63ba1bcdc8c6425ea95b3168a3a5c64d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e01c196bcd9c4830a96dba987d6d6795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6650ae0c2e4f4e94b2abb9fcacfdc548": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60dbb88940c1485bb97a58a6cfa2bc99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88c96fe3fc9545348e088118769dd269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d1cbc84fc949ae811298afa4f88a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Cyber-Attack-Detection/blob/main/SatelliteImageEnvironment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vegetation Monitoring with Sentinel-2 RGB Dataset Using Classical Computer Vision\n",
        "\n",
        "## Project Overview\n",
        "Develop a vegetation monitoring system using the Sentinel-2 RGB captioned dataset with classical computer vision techniques to analyze vegetation cover, health, and changes over time.\n",
        "\n",
        "## Dataset Information\n",
        "**Dataset**: `sshh12/sentinel-2-rgb-captioned` from Hugging Face\n",
        "- **Content**: Pre-processed Sentinel-2 RGB images with captions\n",
        "- **Format**: RGB images (Red, Green, Blue bands)\n",
        "- **Advantages**: Clean, pre-processed data with descriptive captions\n",
        "- **Focus**: Vegetation analysis using visible spectrum\n",
        "\n",
        "## Detailed Workflow\n",
        "\n",
        "### Phase 1: Dataset Setup & Exploration ( 1)\n",
        "**Objectives:**\n",
        "- Load and explore the Sentinel-2 RGB dataset\n",
        "- Understand data structure and captions\n",
        "- Set up vegetation monitoring framework\n",
        "\n",
        "**Tasks:**\n",
        "1. **Dataset Loading**\n",
        "   ```python\n",
        "   from datasets import load_dataset\n",
        "   ds = load_dataset(\"sshh12/sentinel-2-rgb-captioned\")\n",
        "   ```\n",
        "2. **Data Exploration**\n",
        "   - Analyze image dimensions and RGB channel distributions\n",
        "   - Study caption content for vegetation-related keywords\n",
        "   - Create sample visualizations of different vegetation types\n",
        "3. **Environment Setup**\n",
        "   - Install libraries: OpenCV, scikit-image, matplotlib, pandas, numpy\n",
        "   - Set up project structure for vegetation analysis\n",
        "\n",
        "### Phase 2: Vegetation-Focused Preprocessing ( 2)\n",
        "**Objectives:**\n",
        "- Enhance RGB images for vegetation analysis\n",
        "- Extract vegetation-specific features from limited spectral bands\n",
        "\n",
        "**Classical CV Techniques:**\n",
        "1. **RGB Enhancement for Vegetation**\n",
        "   - Histogram equalization on individual channels\n",
        "   - Contrast Limited Adaptive Histogram Equalization (CLAHE)\n",
        "   - Color space conversions (RGB ‚Üí HSV, RGB ‚Üí LAB)\n",
        "\n",
        "2. **Vegetation Index Approximation**\n",
        "   - **Visible Atmospherically Resistant Index (VARI)**: (Green - Red) / (Green + Red - Blue)\n",
        "   - **Green Leaf Index (GLI)**: (2√óGreen - Red - Blue) / (2√óGreen + Red + Blue)\n",
        "   - **Red-Green Ratio**: Red/Green for vegetation stress detection\n",
        "\n",
        "3. **Color-Based Vegetation Enhancement**\n",
        "   - Green channel enhancement\n",
        "   - Color thresholding for vegetation masking\n",
        "   - HSV-based vegetation extraction\n",
        "\n",
        "### Phase 3: Vegetation Feature Extraction ( 3)\n",
        "**Objectives:**\n",
        "- Extract vegetation-specific features from RGB imagery\n",
        "\n",
        "**Classical CV Techniques:**\n",
        "1. **Color-Based Vegetation Features**\n",
        "   - **Green Dominance Analysis**: Quantify green pixel distribution\n",
        "   - **Color Moment Analysis**: Mean, variance, skewness of each channel\n",
        "   - **Color Histogram Features**: Vegetation-specific color patterns\n",
        "\n",
        "2. **Texture Analysis for Vegetation**\n",
        "   - **GLCM on Green Channel**: Vegetation texture characterization\n",
        "   - **Local Binary Patterns (LBP)**: Forest vs. grassland texture differentiation\n",
        "   - **Gabor Filters**: Directional texture analysis for crop patterns\n",
        "\n",
        "3. **Morphological Features**\n",
        "   - **Vegetation Boundary Detection**: Canny edge detection on green-enhanced images\n",
        "   - **Shape Analysis**: Contour analysis for vegetation patches\n",
        "   - **Canopy Structure**: Morphological operations to identify tree crowns\n",
        "\n",
        "4. **Spatial Vegetation Patterns**\n",
        "   - **Vegetation Density Maps**: Green pixel density analysis\n",
        "   - **Patch Size Distribution**: Connected component analysis\n",
        "   - **Fragmentation Metrics**: Edge-to-area ratios\n",
        "\n",
        "### Phase 4: Vegetation Classification & Segmentation ( 4)\n",
        "**Objectives:**\n",
        "- Classify different vegetation types and health conditions\n",
        "\n",
        "**Vegetation Categories:**\n",
        "- Dense Forest\n",
        "- Sparse Forest/Woodland\n",
        "- Grassland/Shrubland\n",
        "- Agricultural Crops\n",
        "- Stressed/Unhealthy Vegetation\n",
        "- Non-Vegetation (Urban, Water, Bare Soil)\n",
        "\n",
        "**Classical CV Techniques:**\n",
        "1. **Color-Based Segmentation**\n",
        "   - **K-means Clustering**: Separate vegetation types by color characteristics\n",
        "   - **HSV Thresholding**: Isolate healthy green vegetation\n",
        "   - **Watershed Segmentation**: Separate individual vegetation patches\n",
        "\n",
        "2. **Machine Learning Classification**\n",
        "   - **Support Vector Machine (SVM)**: Multi-class vegetation classification\n",
        "   - **Random Forest**: Combine multiple vegetation features\n",
        "   - **Decision Trees**: Interpretable vegetation health assessment\n",
        "\n",
        "3. **Rule-Based Classification**\n",
        "   - **Vegetation Index Thresholding**: VARI and GLI-based classification\n",
        "   - **Color Rule Sets**: IF-THEN rules for vegetation types\n",
        "   - **Multi-criteria Decision**: Combine color, texture, and shape features\n",
        "\n",
        "### Phase 5: Vegetation Health Assessment ( 5)\n",
        "**Objectives:**\n",
        "- Assess vegetation health and stress conditions\n",
        "\n",
        "**Classical CV Approaches:**\n",
        "1. **Health Indicators from RGB**\n",
        "   - **Greenness Assessment**: Green channel intensity analysis\n",
        "   - **Color Deviation Analysis**: Deviation from healthy vegetation colors\n",
        "   - **Browning Detection**: Red/Brown pixel identification for stress\n",
        "\n",
        "2. **Vegetation Vigor Analysis**\n",
        "   - **VARI Trend Analysis**: Vegetation activity and vigor\n",
        "   - **Seasonal Color Changes**: Multi-temporal color analysis\n",
        "   - **Stress Pattern Recognition**: Identify yellowing/browning patterns\n",
        "\n",
        "3. **Canopy Analysis**\n",
        "   - **Canopy Coverage**: Percentage of vegetation cover\n",
        "   - **Canopy Density**: Pixel intensity-based density estimation\n",
        "   - **Gap Analysis**: Identify clearings and deforestation\n",
        "\n",
        "### Phase 6: Temporal Vegetation Analysis ( 6)\n",
        "**Objectives:**\n",
        "- Monitor vegetation changes over time using available temporal data\n",
        "\n",
        "**Change Detection Methods:**\n",
        "1. **RGB-Based Change Detection**\n",
        "   - **Image Differencing**: Compare vegetation indices across time\n",
        "   - **Color Change Analysis**: Track color shifts indicating phenology\n",
        "   - **Threshold-Based Change**: Binary change detection\n",
        "\n",
        "2. **Vegetation Trend Analysis**\n",
        "   - **Greenness Trends**: Long-term vegetation health trends\n",
        "   - **Seasonal Pattern Recognition**: Identify phenological cycles\n",
        "   - **Disturbance Detection**: Identify sudden vegetation loss\n",
        "\n",
        "### Phase 7: Validation & Results ( 7)\n",
        "**Objectives:**\n",
        "- Validate results and create comprehensive vegetation analysis\n",
        "\n",
        "**Validation Methods:**\n",
        "1. **Caption-Based Validation**\n",
        "   - Use image captions to validate classification results\n",
        "   - Cross-reference vegetation descriptions with analysis\n",
        "   - Accuracy assessment using caption keywords\n",
        "\n",
        "2. **Visual Validation**\n",
        "   - Expert interpretation of results\n",
        "   - Comparison with known vegetation patterns\n",
        "   - Ground truth validation where available\n",
        "\n",
        "## Technical Implementation Stack\n",
        "\n",
        "### Core Libraries\n",
        "```python\n",
        "# Data handling\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Image processing\n",
        "import cv2\n",
        "from skimage import filters, segmentation, measure, morphology\n",
        "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "```\n",
        "\n",
        "### Key Vegetation Algorithms\n",
        "1. **VARI Calculation**: `(Green - Red) / (Green + Red - Blue)`\n",
        "2. **GLI Calculation**: `(2*Green - Red - Blue) / (2*Green + Red + Blue)`\n",
        "3. **Green Dominance**: `Green / (Red + Green + Blue)`\n",
        "4. **Vegetation Masking**: HSV-based green extraction\n",
        "5. **Canopy Coverage**: Green pixel percentage calculation\n",
        "\n",
        "## Vegetation-Specific Features to Extract\n",
        "\n",
        "### Color Features\n",
        "- Mean, std, skewness of R, G, B channels\n",
        "- VARI and GLI vegetation indices\n",
        "- Green dominance ratio\n",
        "- HSV color moments\n",
        "- Color histogram bins\n",
        "\n",
        "### Texture Features\n",
        "- GLCM properties (contrast, dissimilarity, homogeneity, energy)\n",
        "- LBP histogram for vegetation texture\n",
        "- Gabor filter responses for directional patterns\n",
        "\n",
        "### Morphological Features\n",
        "- Vegetation patch area and perimeter\n",
        "- Compactness and roundness of vegetation areas\n",
        "- Edge density within vegetation regions\n",
        "\n",
        "## Expected Vegetation Classification Results\n",
        "\n",
        "### Vegetation Types to Identify\n",
        "1. **Dense Forest**: High green intensity, coarse texture\n",
        "2. **Open Woodland**: Moderate green, mixed texture\n",
        "3. **Grassland**: Uniform green, fine texture\n",
        "4. **Cropland**: Regular patterns, seasonal color changes\n",
        "5. **Stressed Vegetation**: Yellow/brown tones, reduced green intensity\n",
        "6. **Mixed Vegetation**: Varied color and texture patterns\n",
        "\n",
        "### Performance Metrics\n",
        "- Overall classification accuracy > 80%\n",
        "- Vegetation vs. non-vegetation accuracy > 90%\n",
        "- Healthy vs. stressed vegetation accuracy > 75%\n",
        "- F1-score per vegetation class > 0.7\n",
        "\n",
        "## Sample Code Structure\n",
        "\n",
        "```python\n",
        "# 1. Dataset loading and exploration\n",
        "ds = load_dataset(\"sshh12/sentinel-2-rgb-captioned\")\n",
        "explore_vegetation_dataset(ds)\n",
        "\n",
        "# 2. Preprocessing\n",
        "enhanced_images = preprocess_for_vegetation(ds['image'])\n",
        "vegetation_indices = calculate_vegetation_indices(enhanced_images)\n",
        "\n",
        "# 3. Feature extraction\n",
        "color_features = extract_color_features(enhanced_images)\n",
        "texture_features = extract_texture_features(enhanced_images)\n",
        "vegetation_features = combine_features(color_features, texture_features, vegetation_indices)\n",
        "\n",
        "# 4. Classification\n",
        "vegetation_classifier = train_vegetation_classifier(vegetation_features, labels)\n",
        "vegetation_map = classify_vegetation(test_images)\n",
        "\n",
        "# 5. Analysis and visualization\n",
        "analyze_vegetation_health(vegetation_map)\n",
        "create_vegetation_visualizations(results)\n",
        "```\n",
        "\n",
        "## Final Deliverables\n",
        "1. **Vegetation Classification System**: Automated vegetation type identification\n",
        "2. **Vegetation Health Assessment Tool**: RGB-based health monitoring\n",
        "3. **Vegetation Coverage Analysis**: Quantitative vegetation coverage metrics\n",
        "4. **Temporal Vegetation Monitoring**: Change detection capabilities\n",
        "5. **Comprehensive Report**: Methodology, results, and vegetation insights\n",
        "6. **Interactive Visualizations**: Vegetation maps and health indicators\n",
        "\n",
        "## Success Criteria\n",
        "- Accurate vegetation type classification using only RGB data\n",
        "- Effective vegetation health assessment from color analysis\n",
        "- Reliable vegetation change detection over time\n",
        "- Clear visualization of vegetation patterns and trends\n",
        "- Validation against image captions and expert knowledge"
      ],
      "metadata": {
        "id": "ZIfdUAI94vMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlcroissant"
      ],
      "metadata": {
        "id": "6D89sp_Z-o6X",
        "outputId": "c8699fea-8c76-4cd9-8857-be982506d4a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlcroissant\n",
            "  Downloading mlcroissant-1.0.17-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (1.4.0)\n",
            "Requirement already satisfied: etils>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.7.0->mlcroissant) (1.12.2)\n",
            "Collecting jsonpath-rw (from mlcroissant)\n",
            "  Downloading jsonpath-rw-1.4.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (3.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (2.2.2)\n",
            "Requirement already satisfied: pandas-stubs in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (2.2.2.240909)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (2.9.0.post0)\n",
            "Collecting rdflib (from mlcroissant)\n",
            "  Downloading rdflib-7.1.4-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (2.32.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (1.15.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mlcroissant) (4.67.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.7.0->mlcroissant) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.7.0->mlcroissant) (6.5.2)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.7.0->mlcroissant) (4.14.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath]>=1.7.0->mlcroissant) (3.22.0)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.11/dist-packages (from jsonpath-rw->mlcroissant) (3.11)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from jsonpath-rw->mlcroissant) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from jsonpath-rw->mlcroissant) (1.17.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->mlcroissant) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->mlcroissant) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->mlcroissant) (2025.2)\n",
            "Requirement already satisfied: types-pytz>=2022.1.1 in /usr/local/lib/python3.11/dist-packages (from pandas-stubs->mlcroissant) (2025.2.0.20250516)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from rdflib->mlcroissant) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->mlcroissant) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->mlcroissant) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->mlcroissant) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->mlcroissant) (2025.4.26)\n",
            "Downloading mlcroissant-1.0.17-py2.py3-none-any.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m141.4/141.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rdflib-7.1.4-py3-none-any.whl (565 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m565.1/565.1 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: jsonpath-rw\n",
            "  Building wheel for jsonpath-rw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonpath-rw: filename=jsonpath_rw-1.4.0-py3-none-any.whl size=15127 sha256=ed64276709c68af7de0fd34ad26873f225111d948da1816ee465b7a7a7d5f403\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/cf/51/a4ea10224b7fdb523e18e2033cadf2a8657517d1f95f3f5413\n",
            "Successfully built jsonpath-rw\n",
            "Installing collected packages: rdflib, jsonpath-rw, mlcroissant\n",
            "Successfully installed jsonpath-rw-1.4.0 mlcroissant-1.0.17 rdflib-7.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mlcroissant import Dataset\n",
        "\n",
        "# The Croissant metadata exposes the first 5GB of this dataset\n",
        "ds = Dataset(jsonld=\"https://huggingface.co/api/datasets/sshh12/sentinel-2-rgb-captioned/croissant\")\n",
        "records = ds.records(\"default\")"
      ],
      "metadata": {
        "id": "g5bAbea3-ms0",
        "outputId": "a0b2adbf-01d0-4a51-a06b-62d6b82a090b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mlcroissant'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4219175184>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlcroissant\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# The Croissant metadata exposes the first 5GB of this dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonld\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"https://huggingface.co/api/datasets/sshh12/sentinel-2-rgb-captioned/croissant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlcroissant'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7NLIG-D24YZ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "063f5db9ea5449b89be540f6545f4fa6",
            "5faccd02f3284d929349b4df686672f7",
            "ff06aa9d6c1e4ae28556c2f0873be096",
            "8cfdd7d4c956467e944ef99b72142a3f",
            "8c0918fb5fec4a9cac47a10964a1f13a",
            "63ba1bcdc8c6425ea95b3168a3a5c64d",
            "e01c196bcd9c4830a96dba987d6d6795",
            "6650ae0c2e4f4e94b2abb9fcacfdc548",
            "60dbb88940c1485bb97a58a6cfa2bc99",
            "88c96fe3fc9545348e088118769dd269",
            "c3d1cbc84fc949ae811298afa4f88a6e"
          ]
        },
        "outputId": "71cd8cc8-d3a1-4482-96e2-417ae7238baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.4.26)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,553 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,246 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,296 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.8 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,986 kB]\n",
            "Fetched 9,520 kB in 3s (3,642 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libgl1-mesa-glx is already the newest version (23.0.4-0ubuntu1~22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "‚úÖ Environment setup complete!\n",
            "üåø PHASE 1: Dataset Setup & Exploration\n",
            "==================================================\n",
            "Loading Sentinel-2 RGB dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/880 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "063f5db9ea5449b89be540f6545f4fa6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Error loading dataset: Invalid pattern: '**' can only be an entire path component\n",
            "Please check your internet connection and try again.\n",
            "\n",
            "üìã Dataset Structure:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ds' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3226627719>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Display dataset structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nüìã Dataset Structure:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Features: {ds.features}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column names: {ds.column_names}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# VEGETATION MONITORING WITH SENTINEL-2 RGB DATASET - PHASES 1-3\n",
        "# Google Colab Notebook\n",
        "# =============================================================================\n",
        "\n",
        "#%% CELL 1: Environment Setup and Installations\n",
        "\"\"\"\n",
        "Install required packages for vegetation monitoring project\n",
        "\"\"\"\n",
        "!pip install datasets transformers opencv-python scikit-image matplotlib seaborn pandas numpy scikit-learn pillow\n",
        "!apt-get update\n",
        "!apt-get install libgl1-mesa-glx -y\n",
        "\n",
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ Environment setup complete!\")\n",
        "\n",
        "#%% CELL 2: Dataset Loading and Initial Setup\n",
        "\"\"\"\n",
        "PHASE 1: Dataset Setup & Exploration\n",
        "Load and explore the Sentinel-2 RGB dataset\n",
        "\"\"\"\n",
        "from datasets import load_dataset\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "print(\"üåø PHASE 1: Dataset Setup & Exploration\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Load the Sentinel-2 RGB captioned dataset\n",
        "print(\"Loading Sentinel-2 RGB dataset...\")\n",
        "try:\n",
        "    ds = load_dataset(\"sshh12/sentinel-2-rgb-captioned\", split=\"train[:1000]\")  # Load first 1000 samples\n",
        "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
        "    print(f\"üìä Dataset size: {len(ds)} samples\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error loading dataset: {e}\")\n",
        "    print(\"Please check your internet connection and try again.\")\n",
        "\n",
        "# Display dataset structure\n",
        "print(\"\\nüìã Dataset Structure:\")\n",
        "print(f\"Features: {ds.features}\")\n",
        "print(f\"Column names: {ds.column_names}\")\n",
        "\n",
        "#%% CELL 3: Dataset Exploration and Analysis\n",
        "\"\"\"\n",
        "Explore dataset content and analyze vegetation-related information\n",
        "\"\"\"\n",
        "print(\"\\nüîç Dataset Content Analysis:\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Sample a few examples\n",
        "sample_indices = random.sample(range(len(ds)), min(5, len(ds)))\n",
        "print(f\"Analyzing {len(sample_indices)} random samples...\\n\")\n",
        "\n",
        "vegetation_keywords = ['forest', 'tree', 'vegetation', 'green', 'grass', 'crop', 'field', 'plant', 'canopy', 'agricultural']\n",
        "caption_analysis = []\n",
        "\n",
        "for i, idx in enumerate(sample_indices):\n",
        "    sample = ds[idx]\n",
        "    image = sample['image']\n",
        "    caption = sample.get('text', 'No caption available')\n",
        "\n",
        "    print(f\"Sample {i+1} (Index {idx}):\")\n",
        "    print(f\"  Caption: {caption}\")\n",
        "    print(f\"  Image size: {image.size}\")\n",
        "    print(f\"  Image mode: {image.mode}\")\n",
        "\n",
        "    # Check for vegetation keywords in caption\n",
        "    veg_found = [kw for kw in vegetation_keywords if kw.lower() in caption.lower()]\n",
        "    if veg_found:\n",
        "        print(f\"  üå± Vegetation keywords found: {veg_found}\")\n",
        "\n",
        "    caption_analysis.append({\n",
        "        'index': idx,\n",
        "        'caption': caption,\n",
        "        'vegetation_keywords': veg_found,\n",
        "        'image_size': image.size\n",
        "    })\n",
        "    print()\n",
        "\n",
        "# Create analysis dataframe\n",
        "analysis_df = pd.DataFrame(caption_analysis)\n",
        "print(f\"üìà Analysis complete for {len(analysis_df)} samples\")\n",
        "\n",
        "#%% CELL 4: Vegetation Keywords Analysis\n",
        "\"\"\"\n",
        "Analyze captions for vegetation-related content\n",
        "\"\"\"\n",
        "print(\"\\nüè∑Ô∏è Caption Analysis for Vegetation Content:\")\n",
        "print(\"=\"*45)\n",
        "\n",
        "# Collect all captions\n",
        "all_captions = [ds[i]['text'] for i in range(min(500, len(ds)))]  # Analyze first 500 captions\n",
        "\n",
        "# Count vegetation keywords\n",
        "vegetation_counts = Counter()\n",
        "for caption in all_captions:\n",
        "    for keyword in vegetation_keywords:\n",
        "        if keyword.lower() in caption.lower():\n",
        "            vegetation_counts[keyword] += 1\n",
        "\n",
        "print(\"üåø Vegetation keyword frequency:\")\n",
        "for keyword, count in vegetation_counts.most_common():\n",
        "    percentage = (count / len(all_captions)) * 100\n",
        "    print(f\"  {keyword}: {count} occurrences ({percentage:.1f}%)\")\n",
        "\n",
        "# Visualize keyword frequency\n",
        "if vegetation_counts:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    keywords = list(vegetation_counts.keys())\n",
        "    counts = list(vegetation_counts.values())\n",
        "\n",
        "    plt.bar(keywords, counts, color='green', alpha=0.7)\n",
        "    plt.title('Vegetation Keywords Frequency in Captions', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Keywords')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "#%% CELL 5: Image Visualization Setup\n",
        "\"\"\"\n",
        "Create visualization functions for RGB images and analysis\n",
        "\"\"\"\n",
        "def display_rgb_images(dataset, indices, figsize=(15, 10)):\n",
        "    \"\"\"Display multiple RGB images with their captions\"\"\"\n",
        "    n_images = len(indices)\n",
        "    cols = min(3, n_images)\n",
        "    rows = (n_images + cols - 1) // cols\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
        "    if n_images == 1:\n",
        "        axes = [axes]\n",
        "    elif rows == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        row = i // cols\n",
        "        col = i % cols\n",
        "\n",
        "        sample = dataset[idx]\n",
        "        image = np.array(sample['image'])\n",
        "        caption = sample.get('text', 'No caption')\n",
        "\n",
        "        if rows > 1:\n",
        "            ax = axes[row, col]\n",
        "        else:\n",
        "            ax = axes[col]\n",
        "\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(f'Sample {idx}\\n{caption[:60]}...', fontsize=10)\n",
        "        ax.axis('off')\n",
        "\n",
        "    # Hide empty subplots\n",
        "    for i in range(n_images, rows * cols):\n",
        "        row = i // cols\n",
        "        col = i % cols\n",
        "        if rows > 1:\n",
        "            axes[row, col].axis('off')\n",
        "        else:\n",
        "            axes[col].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_rgb_channels(image_array):\n",
        "    \"\"\"Analyze RGB channel statistics\"\"\"\n",
        "    r_channel = image_array[:, :, 0]\n",
        "    g_channel = image_array[:, :, 1]\n",
        "    b_channel = image_array[:, :, 2]\n",
        "\n",
        "    stats = {\n",
        "        'Red': {'mean': np.mean(r_channel), 'std': np.std(r_channel), 'max': np.max(r_channel)},\n",
        "        'Green': {'mean': np.mean(g_channel), 'std': np.std(g_channel), 'max': np.max(g_channel)},\n",
        "        'Blue': {'mean': np.mean(b_channel), 'std': np.std(b_channel), 'max': np.max(b_channel)}\n",
        "    }\n",
        "    return stats\n",
        "\n",
        "print(\"‚úÖ Visualization functions created!\")\n",
        "\n",
        "#%% CELL 6: Sample Image Display and Analysis\n",
        "\"\"\"\n",
        "Display sample images and analyze their RGB characteristics\n",
        "\"\"\"\n",
        "print(\"\\nüñºÔ∏è Sample Image Display and RGB Analysis:\")\n",
        "print(\"=\"*45)\n",
        "\n",
        "# Select diverse samples for display\n",
        "display_indices = random.sample(range(len(ds)), min(6, len(ds)))\n",
        "print(f\"Displaying {len(display_indices)} sample images...\")\n",
        "\n",
        "# Display images\n",
        "display_rgb_images(ds, display_indices)\n",
        "\n",
        "# Analyze RGB characteristics of sample images\n",
        "print(\"\\nüìä RGB Channel Analysis:\")\n",
        "rgb_stats_all = []\n",
        "\n",
        "for i, idx in enumerate(display_indices[:3]):  # Analyze first 3 images\n",
        "    sample = ds[idx]\n",
        "    image_array = np.array(sample['image'])\n",
        "    caption = sample.get('text', 'No caption')\n",
        "\n",
        "    stats = analyze_rgb_channels(image_array)\n",
        "    rgb_stats_all.append({\n",
        "        'sample_id': idx,\n",
        "        'caption': caption[:50] + '...',\n",
        "        'stats': stats\n",
        "    })\n",
        "\n",
        "    print(f\"\\nSample {idx}:\")\n",
        "    print(f\"Caption: {caption[:50]}...\")\n",
        "    for channel, values in stats.items():\n",
        "        print(f\"  {channel}: Mean={values['mean']:.1f}, Std={values['std']:.1f}, Max={values['max']}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Phase 1 Complete: Dataset loaded and explored!\")\n",
        "\n",
        "#%% CELL 7: PHASE 2 - Vegetation-Focused Preprocessing Setup\n",
        "\"\"\"\n",
        "PHASE 2: Vegetation-Focused Preprocessing\n",
        "Set up image enhancement and vegetation index calculation functions\n",
        "\"\"\"\n",
        "print(\"\\nüå± PHASE 2: Vegetation-Focused Preprocessing\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def enhance_rgb_for_vegetation(image_array):\n",
        "    \"\"\"\n",
        "    Enhance RGB image for vegetation analysis\n",
        "    \"\"\"\n",
        "    # Convert to float for processing\n",
        "    img_float = image_array.astype(np.float32) / 255.0\n",
        "\n",
        "    # Histogram equalization on individual channels\n",
        "    img_eq = np.zeros_like(img_float)\n",
        "    for i in range(3):\n",
        "        # Convert back to uint8 for CLAHE\n",
        "        channel_uint8 = (img_float[:,:,i] * 255).astype(np.uint8)\n",
        "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "        img_eq[:,:,i] = clahe.apply(channel_uint8) / 255.0\n",
        "\n",
        "    return img_eq\n",
        "\n",
        "def calculate_vegetation_indices(image_array):\n",
        "    \"\"\"\n",
        "    Calculate vegetation indices from RGB image\n",
        "    \"\"\"\n",
        "    # Normalize to 0-1 range\n",
        "    img = image_array.astype(np.float32) / 255.0\n",
        "\n",
        "    red = img[:,:,0]\n",
        "    green = img[:,:,1]\n",
        "    blue = img[:,:,2]\n",
        "\n",
        "    # Avoid division by zero\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    # Visible Atmospherically Resistant Index (VARI)\n",
        "    denominator_vari = green + red - blue + epsilon\n",
        "    vari = (green - red) / denominator_vari\n",
        "\n",
        "    # Green Leaf Index (GLI)\n",
        "    denominator_gli = 2*green + red + blue + epsilon\n",
        "    gli = (2*green - red - blue) / denominator_gli\n",
        "\n",
        "    # Red-Green Ratio\n",
        "    rg_ratio = red / (green + epsilon)\n",
        "\n",
        "    # Green Dominance\n",
        "    total_intensity = red + green + blue + epsilon\n",
        "    green_dominance = green / total_intensity\n",
        "\n",
        "    return {\n",
        "        'vari': vari,\n",
        "        'gli': gli,\n",
        "        'rg_ratio': rg_ratio,\n",
        "        'green_dominance': green_dominance\n",
        "    }\n",
        "\n",
        "def convert_color_spaces(image_array):\n",
        "    \"\"\"\n",
        "    Convert RGB to different color spaces for vegetation analysis\n",
        "    \"\"\"\n",
        "    # Convert to HSV\n",
        "    hsv = cv2.cvtColor(image_array, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    # Convert to LAB\n",
        "    lab = cv2.cvtColor(image_array, cv2.COLOR_RGB2LAB)\n",
        "\n",
        "    return {\n",
        "        'hsv': hsv,\n",
        "        'lab': lab\n",
        "    }\n",
        "\n",
        "def create_vegetation_mask(image_array, method='hsv'):\n",
        "    \"\"\"\n",
        "    Create vegetation mask using color thresholding\n",
        "    \"\"\"\n",
        "    if method == 'hsv':\n",
        "        hsv = cv2.cvtColor(image_array, cv2.COLOR_RGB2HSV)\n",
        "        # Define range for green colors (vegetation)\n",
        "        lower_green = np.array([35, 30, 30])\n",
        "        upper_green = np.array([85, 255, 255])\n",
        "        mask = cv2.inRange(hsv, lower_green, upper_green)\n",
        "\n",
        "    elif method == 'green_threshold':\n",
        "        # Simple green channel thresholding\n",
        "        green_channel = image_array[:,:,1]\n",
        "        red_channel = image_array[:,:,0]\n",
        "        blue_channel = image_array[:,:,2]\n",
        "\n",
        "        # Vegetation typically has high green and lower red/blue\n",
        "        mask = (green_channel > red_channel) & (green_channel > blue_channel) & (green_channel > 100)\n",
        "        mask = mask.astype(np.uint8) * 255\n",
        "\n",
        "    return mask\n",
        "\n",
        "print(\"‚úÖ Vegetation preprocessing functions created!\")\n",
        "\n",
        "#%% CELL 8: Apply Preprocessing to Sample Images\n",
        "\"\"\"\n",
        "Apply vegetation-focused preprocessing to sample images\n",
        "\"\"\"\n",
        "print(\"\\nüîß Applying Preprocessing to Sample Images:\")\n",
        "print(\"=\"*45)\n",
        "\n",
        "# Select a sample for preprocessing demonstration\n",
        "sample_idx = random.choice(range(len(ds)))\n",
        "sample = ds[sample_idx]\n",
        "original_image = np.array(sample['image'])\n",
        "caption = sample.get('text', 'No caption')\n",
        "\n",
        "print(f\"Processing sample {sample_idx}: {caption[:50]}...\")\n",
        "\n",
        "# Apply preprocessing steps\n",
        "enhanced_image = enhance_rgb_for_vegetation(original_image)\n",
        "vegetation_indices = calculate_vegetation_indices(original_image)\n",
        "color_spaces = convert_color_spaces(original_image)\n",
        "vegetation_mask = create_vegetation_mask(original_image, method='hsv')\n",
        "\n",
        "# Create visualization\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "\n",
        "# Original image\n",
        "axes[0,0].imshow(original_image)\n",
        "axes[0,0].set_title('Original RGB')\n",
        "axes[0,0].axis('off')\n",
        "\n",
        "# Enhanced image\n",
        "axes[0,1].imshow(enhanced_image)\n",
        "axes[0,1].set_title('Enhanced RGB')\n",
        "axes[0,1].axis('off')\n",
        "\n",
        "# HSV\n",
        "axes[0,2].imshow(color_spaces['hsv'])\n",
        "axes[0,2].set_title('HSV Color Space')\n",
        "axes[0,2].axis('off')\n",
        "\n",
        "# Vegetation mask\n",
        "axes[0,3].imshow(vegetation_mask, cmap='gray')\n",
        "axes[0,3].set_title('Vegetation Mask')\n",
        "axes[0,3].axis('off')\n",
        "\n",
        "# Vegetation indices\n",
        "im1 = axes[1,0].imshow(vegetation_indices['vari'], cmap='RdYlGn', vmin=-1, vmax=1)\n",
        "axes[1,0].set_title('VARI Index')\n",
        "axes[1,0].axis('off')\n",
        "plt.colorbar(im1, ax=axes[1,0], fraction=0.046)\n",
        "\n",
        "im2 = axes[1,1].imshow(vegetation_indices['gli'], cmap='RdYlGn', vmin=-1, vmax=1)\n",
        "axes[1,1].set_title('GLI Index')\n",
        "axes[1,1].axis('off')\n",
        "plt.colorbar(im2, ax=axes[1,1], fraction=0.046)\n",
        "\n",
        "im3 = axes[1,2].imshow(vegetation_indices['green_dominance'], cmap='Greens', vmin=0, vmax=1)\n",
        "axes[1,2].set_title('Green Dominance')\n",
        "axes[1,2].axis('off')\n",
        "plt.colorbar(im3, ax=axes[1,2], fraction=0.046)\n",
        "\n",
        "im4 = axes[1,3].imshow(vegetation_indices['rg_ratio'], cmap='RdYlGn_r', vmin=0, vmax=2)\n",
        "axes[1,3].set_title('Red/Green Ratio')\n",
        "axes[1,3].axis('off')\n",
        "plt.colorbar(im4, ax=axes[1,3], fraction=0.046)\n",
        "\n",
        "plt.suptitle(f'Vegetation Preprocessing Results\\nSample {sample_idx}: {caption[:60]}...', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print vegetation index statistics\n",
        "print(f\"\\nüìä Vegetation Index Statistics for Sample {sample_idx}:\")\n",
        "for index_name, index_values in vegetation_indices.items():\n",
        "    print(f\"  {index_name.upper()}: Mean={np.mean(index_values):.3f}, Std={np.std(index_values):.3f}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Phase 2 Complete: Preprocessing applied successfully!\")\n",
        "\n",
        "#%% CELL 9: PHASE 3 - Feature Extraction Setup\n",
        "\"\"\"\n",
        "PHASE 3: Vegetation Feature Extraction\n",
        "Set up feature extraction functions for vegetation analysis\n",
        "\"\"\"\n",
        "from skimage.feature import graycomatrix, graycoprops, local_binary_pattern\n",
        "from skimage import measure\n",
        "from scipy import ndimage\n",
        "\n",
        "print(\"\\nüî¨ PHASE 3: Vegetation Feature Extraction\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "def extract_color_features(image_array):\n",
        "    \"\"\"\n",
        "    Extract color-based features for vegetation analysis\n",
        "    \"\"\"\n",
        "    # Convert to float\n",
        "    img = image_array.astype(np.float32) / 255.0\n",
        "\n",
        "    features = {}\n",
        "\n",
        "    # Basic color statistics for each channel\n",
        "    for i, channel in enumerate(['red', 'green', 'blue']):\n",
        "        channel_data = img[:,:,i]\n",
        "        features[f'{channel}_mean'] = np.mean(channel_data)\n",
        "        features[f'{channel}_std'] = np.std(channel_data)\n",
        "        features[f'{channel}_skewness'] = scipy.stats.skew(channel_data.flatten()) if 'scipy.stats' in globals() else 0\n",
        "        features[f'{channel}_max'] = np.max(channel_data)\n",
        "        features[f'{channel}_min'] = np.min(channel_data)\n",
        "\n",
        "    # Color ratios important for vegetation\n",
        "    red, green, blue = img[:,:,0], img[:,:,1], img[:,:,2]\n",
        "    epsilon = 1e-8\n",
        "\n",
        "    features['green_red_ratio'] = np.mean(green / (red + epsilon))\n",
        "    features['green_blue_ratio'] = np.mean(green / (blue + epsilon))\n",
        "    features['red_green_ratio'] = np.mean(red / (green + epsilon))\n",
        "\n",
        "    # Green dominance\n",
        "    total_intensity = red + green + blue + epsilon\n",
        "    features['green_dominance_mean'] = np.mean(green / total_intensity)\n",
        "    features['green_dominance_std'] = np.std(green / total_intensity)\n",
        "\n",
        "    return features\n",
        "\n",
        "def extract_vegetation_indices_features(image_array):\n",
        "    \"\"\"\n",
        "    Extract features based on vegetation indices\n",
        "    \"\"\"\n",
        "    indices = calculate_vegetation_indices(image_array)\n",
        "    features = {}\n",
        "\n",
        "    for index_name, index_values in indices.items():\n",
        "        features[f'{index_name}_mean'] = np.mean(index_values)\n",
        "        features[f'{index_name}_std'] = np.std(index_values)\n",
        "        features[f'{index_name}_median'] = np.median(index_values)\n",
        "        features[f'{index_name}_range'] = np.max(index_values) - np.min(index_values)\n",
        "\n",
        "        # Percentiles\n",
        "        features[f'{index_name}_p25'] = np.percentile(index_values, 25)\n",
        "        features[f'{index_name}_p75'] = np.percentile(index_values, 75)\n",
        "\n",
        "    return features\n",
        "\n",
        "def extract_texture_features(image_array):\n",
        "    \"\"\"\n",
        "    Extract texture features for vegetation analysis\n",
        "    \"\"\"\n",
        "    # Convert to grayscale (using green channel as it's most relevant for vegetation)\n",
        "    if len(image_array.shape) == 3:\n",
        "        gray = image_array[:,:,1]  # Green channel\n",
        "    else:\n",
        "        gray = image_array\n",
        "\n",
        "    # Normalize to 0-255 range for texture analysis\n",
        "    gray_norm = ((gray - gray.min()) / (gray.max() - gray.min()) * 255).astype(np.uint8)\n",
        "\n",
        "    features = {}\n",
        "\n",
        "    # GLCM texture features\n",
        "    try:\n",
        "        # Calculate GLCM\n",
        "        distances = [1, 2]\n",
        "        angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
        "\n",
        "        glcm = graycomatrix(gray_norm, distances=distances, angles=angles,\n",
        "                           levels=256, symmetric=True, normed=True)\n",
        "\n",
        "        # Calculate texture properties\n",
        "        properties = ['dissimilarity', 'correlation', 'homogeneity', 'contrast', 'energy']\n",
        "\n",
        "        for prop in properties:\n",
        "            prop_values = graycoprops(glcm, prop)\n",
        "            features[f'glcm_{prop}_mean'] = np.mean(prop_values)\n",
        "            features[f'glcm_{prop}_std'] = np.std(prop_values)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: GLCM calculation failed: {e}\")\n",
        "        # Set default values\n",
        "        for prop in ['dissimilarity', 'correlation', 'homogeneity', 'contrast', 'energy']:\n",
        "            features[f'glcm_{prop}_mean'] = 0\n",
        "            features[f'glcm_{prop}_std'] = 0\n",
        "\n",
        "    # Local Binary Pattern\n",
        "    try:\n",
        "        radius = 3\n",
        "        n_points = 8 * radius\n",
        "        lbp = local_binary_pattern(gray_norm, n_points, radius, method='uniform')\n",
        "\n",
        "        # LBP histogram\n",
        "        lbp_hist, _ = np.histogram(lbp.ravel(), bins=n_points + 2,\n",
        "                                  range=(0, n_points + 2), density=True)\n",
        "\n",
        "        features['lbp_uniformity'] = np.sum(lbp_hist ** 2)\n",
        "        features['lbp_entropy'] = -np.sum(lbp_hist * np.log(lbp_hist + 1e-8))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: LBP calculation failed: {e}\")\n",
        "        features['lbp_uniformity'] = 0\n",
        "        features['lbp_entropy'] = 0\n",
        "\n",
        "    return features\n",
        "\n",
        "def extract_morphological_features(image_array):\n",
        "    \"\"\"\n",
        "    Extract morphological features for vegetation analysis\n",
        "    \"\"\"\n",
        "    # Create vegetation mask\n",
        "    veg_mask = create_vegetation_mask(image_array, method='hsv')\n",
        "\n",
        "    features = {}\n",
        "\n",
        "    # Basic morphological properties\n",
        "    features['vegetation_coverage'] = np.sum(veg_mask > 0) / veg_mask.size\n",
        "\n",
        "    try:\n",
        "        # Connected components analysis\n",
        "        labeled_mask = measure.label(veg_mask > 0)\n",
        "        props = measure.regionprops(labeled_mask)\n",
        "\n",
        "        if props:\n",
        "            areas = [prop.area for prop in props]\n",
        "            features['num_vegetation_patches'] = len(props)\n",
        "            features['mean_patch_area'] = np.mean(areas)\n",
        "            features['std_patch_area'] = np.std(areas)\n",
        "            features['largest_patch_area'] = np.max(areas)\n",
        "\n",
        "            # Shape features\n",
        "            eccentricities = [prop.eccentricity for prop in props]\n",
        "            solidities = [prop.solidity for prop in props]\n",
        "\n",
        "            features['mean_eccentricity'] = np.mean(eccentricities)\n",
        "            features['mean_solidity'] = np.mean(solidities)\n",
        "        else:\n",
        "            # No vegetation patches found\n",
        "            features['num_vegetation_patches'] = 0\n",
        "            features['mean_patch_area'] = 0\n",
        "            features['std_patch_area'] = 0\n",
        "            features['largest_patch_area'] = 0\n",
        "            features['mean_eccentricity'] = 0\n",
        "            features['mean_solidity'] = 0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Morphological analysis failed: {e}\")\n",
        "        # Set default values\n",
        "        for key in ['num_vegetation_patches', 'mean_patch_area', 'std_patch_area',\n",
        "                   'largest_patch_area', 'mean_eccentricity', 'mean_solidity']:\n",
        "            features[key] = 0\n",
        "\n",
        "    return features\n",
        "\n",
        "def extract_all_vegetation_features(image_array):\n",
        "    \"\"\"\n",
        "    Extract all vegetation-related features from an image\n",
        "    \"\"\"\n",
        "    color_features = extract_color_features(image_array)\n",
        "    vegetation_features = extract_vegetation_indices_features(image_array)\n",
        "    texture_features = extract_texture_features(image_array)\n",
        "    morphological_features = extract_morphological_features(image_array)\n",
        "\n",
        "    # Combine all features\n",
        "    all_features = {}\n",
        "    all_features.update(color_features)\n",
        "    all_features.update(vegetation_features)\n",
        "    all_features.update(texture_features)\n",
        "    all_features.update(morphological_features)\n",
        "\n",
        "    return all_features\n",
        "\n",
        "# Import scipy.stats if available\n",
        "try:\n",
        "    import scipy.stats\n",
        "    print(\"‚úÖ SciPy available for advanced statistics\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è SciPy not available, skipping skewness calculation\")\n",
        "\n",
        "print(\"‚úÖ Feature extraction functions created!\")\n",
        "\n",
        "#%% CELL 10: Extract Features from Sample Images\n",
        "\"\"\"\n",
        "Extract features from sample images to demonstrate the feature extraction pipeline\n",
        "\"\"\"\n",
        "print(\"\\nüîç Extracting Features from Sample Images:\")\n",
        "print(\"=\"*45)\n",
        "\n",
        "# Select samples for feature extraction\n",
        "feature_sample_indices = random.sample(range(len(ds)), min(5, len(ds)))\n",
        "all_sample_features = []\n",
        "\n",
        "print(f\"Extracting features from {len(feature_sample_indices)} samples...\\n\")\n",
        "\n",
        "for i, idx in enumerate(feature_sample_indices):\n",
        "    print(f\"Processing sample {i+1}/{len(feature_sample_indices)} (Index {idx})...\")\n",
        "\n",
        "    sample = ds[idx]\n",
        "    image_array = np.array(sample['image'])\n",
        "    caption = sample.get('text', 'No caption')\n",
        "\n",
        "    # Extract all features\n",
        "    features = extract_all_vegetation_features(image_array)\n",
        "    features['sample_id'] = idx\n",
        "    features['caption'] = caption\n",
        "\n",
        "    all_sample_features.append(features)\n",
        "\n",
        "    print(f\"  ‚úÖ Extracted {len(features)-2} features\")  # -2 for sample_id and caption\n",
        "\n",
        "# Create feature dataframe\n",
        "feature_df = pd.DataFrame(all_sample_features)\n",
        "print(f\"\\nüìä Feature Extraction Summary:\")\n",
        "print(f\"  Total samples processed: {len(feature_df)}\")\n",
        "print(f\"  Total features per sample: {len(feature_df.columns)-2}\")\n",
        "\n",
        "# Display feature categories\n",
        "color_features = [col for col in feature_df.columns if any(color in col for color in ['red', 'green', 'blue', 'ratio', 'dominance'])]\n",
        "vegetation_features = [col for col in feature_df.columns if any(vi in col for vi in ['vari', 'gli', 'rg_ratio', 'green_dominance'])]\n",
        "texture_features = [col for col in feature_df.columns if any(tex in col for tex in ['glcm', 'lbp'])]\n",
        "morphological_features = [col for col in feature_df.columns if any(morph in col for morph in ['patch', 'coverage', 'eccentricity', 'solidity'])]\n",
        "\n",
        "print(f\"\\nüé® Feature Categories:\")\n",
        "print(f\"  Color features: {len(color_features)}\")\n",
        "print(f\"  Vegetation index features: {len(vegetation_features)}\")\n",
        "print(f\"  Texture features: {len(texture_features)}\")\n",
        "print(f\"  Morphological features: {len(morphological_features)}\")\n",
        "\n",
        "#%% CELL 11: Feature Analysis and Visualization\n",
        "\"\"\"\n",
        "Analyze and visualize the extracted features\n",
        "\"\"\"\n",
        "print(\"\\nüìà Feature Analysis and Visualization:\")\n",
        "print(\"=\"*45)\n",
        "\n",
        "# Select key features for visualization\n",
        "key_features = ['green_mean', 'vari_mean', 'gli_mean', 'vegetation_coverage',\n",
        "                'glcm_contrast_mean', 'num_vegetation_patches']\n",
        "\n",
        "# Check which features are available\n",
        "available_key_features = [f for f in key_features if f in feature_df.columns]\n",
        "print(f\"Analyzing {len(available_key_features)} key features: {available_key_features}\")\n",
        "\n",
        "if available_key_features:\n",
        "    # Create correlation matrix for key features\n",
        "    correlation_matrix = feature_df[available_key_features].corr()\n",
        "\n",
        "    # Visualize feature distributions and correlations\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "    # Feature distributions\n",
        "    feature_df[available_key_features].hist(bins=20, ax=axes[0,0], figsize=(8, 6))\n",
        "    axes[0,0].set_title('Feature Distributions')\n",
        "\n",
        "    # Correlation heatmap\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "                ax=axes[0,1], square=True)\n",
        "    axes[0,1].set_title('Feature Correlations')\n",
        "\n",
        "    # Vegetation coverage vs other features\n",
        "    if 'vegetation_coverage' in available_key_features and len(available_key_features) > 1:\n",
        "        other_feature = [f for f in available_key_features if f != 'vegetation_coverage'][0]\n",
        "        axes[1,0].scatter(feature_df['vegetation_coverage'], feature_df[other_feature], alpha=0.7)\n",
        "        axes[1,0].set_xlabel('Vegetation Coverage')\n",
        "        axes[1,0].set_ylabel(other_feature.replace('_', ' ').title())\n",
        "        axes[1,0].set_title(f'Vegetation Coverage vs {other_feature.replace(\"_\", \" \").title()}')\n",
        "\n",
        "    # Feature summary statistics\n",
        "    summary_stats = feature_df[available_key_features].describe()\n",
        "    axes[1,1].axis('tight')\n",
        "    axes[1,1].axis('off')\n",
        "    table = axes[1,1].table(cellText=summary_stats.round(3).values,\n",
        "                           rowLabels=summary_stats.index,\n",
        "                           colLabels=[col.replace('_', '\\n') for col in summary_stats.columns],\n",
        "                           cellLoc='center',\n",
        "                           loc='center')\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(8)\n",
        "    axes[1,1].set_title('Feature Summary Statistics')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display detailed feature statistics\n",
        "print(f\"\\nüìä Detailed Feature Statistics:\")\n",
        "numeric_features = feature_df.select_dtypes(include=[np.number]).columns\n",
        "if len(numeric_features) > 0:\n",
        "    print(f\"Mean feature values across {len(feature_df)} samples:\")\n",
        "    feature_means = feature_df[numeric_features].mean().sort_values(ascending=False)\n",
        "\n",
        "    for feature, value in feature_means.head(10).items():\n",
        "        print(f\"  {feature}: {value:.4f}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Phase 3 Complete: Feature extraction and analysis finished!\")\n",
        "\n",
        "#%% CELL 12: Summary and Next Steps\n",
        "\"\"\"\n",
        "Summary of Phases 1-3 and preparation for next phases\n",
        "\"\"\"\n",
        "print(\"\\nüéØ PROJECT SUMMARY - PHASES 1-3 COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"‚úÖ PHASE 1 - Dataset Setup & Exploration:\")\n",
        "print(f\"   ‚Ä¢ Loaded Sentinel-2 RGB dataset with {len(ds)} samples\")\n",
        "print(f\"   ‚Ä¢ Analyzed vegetation keywords in captions\")\n",
        "print(f\"   ‚Ä¢ Explored RGB image characteristics\")\n",
        "\n",
        "print(\"\\n‚úÖ PHASE 2 - Vegetation-Focused Preprocessing:\")\n",
        "print(\"   ‚Ä¢ Implemented RGB enhancement for vegetation analysis\")\n",
        "print(\"   ‚Ä¢ Created vegetation indices (VARI, GLI, RG-ratio, Green dominance)\")\n",
        "print(\"   ‚Ä¢ Developed color space conversions (HSV, LAB)\")\n",
        "print(\"   ‚Ä¢ Created vegetation masking functions\")\n",
        "\n",
        "print(\"\\n‚úÖ PHASE 3 - Vegetation Feature Extraction:\")\n",
        "print(\"   ‚Ä¢ Extracted color-based features (RGB statistics, ratios)\")\n",
        "print(\"   ‚Ä¢ Calculated vegetation index features (statistics, percentiles)\")\n",
        "print(\"   ‚Ä¢ Implemented texture analysis (GLCM, LBP)\")\n",
        "print(\"   ‚Ä¢ Developed morphological features (patch analysis, coverage)\")\n",
        "\n",
        "# Create feature summary for export\n",
        "if len(all_sample_features) > 0:\n",
        "    print(f\"\\nüìã FEATURE EXTRACTION RESULTS:\")\n",
        "    print(f\"   ‚Ä¢ Total samples processed: {len(all_sample_features)}\")\n",
        "    print(f\"   ‚Ä¢ Features per sample: {len(all_sample_features[0])-2}\")\n",
        "    print(f\"   ‚Ä¢ Feature categories: Color, Vegetation Indices, Texture, Morphological\")\n",
        "\n",
        "print(f\"\\nüöÄ READY FOR NEXT PHASES:\")\n",
        "print(\"   ‚Ä¢ Phase 4: Vegetation Classification & Segmentation\")\n",
        "print(\"   ‚Ä¢ Phase 5: Vegetation Health Assessment\")\n",
        "print(\"   ‚Ä¢ Phase 6: Temporal Vegetation Analysis\")\n",
        "print(\"   ‚Ä¢ Phase 7: Validation & Results\")\n",
        "\n",
        "# Save processed data for next phases\n",
        "processed_data = {\n",
        "    'dataset_size': len(ds),\n",
        "    'sample_features': all_sample_features,\n",
        "    'feature_columns': list(feature_df.columns) if 'feature_df' in locals() else [],\n",
        "    'vegetation_keywords_found': dict(vegetation_counts) if 'vegetation_counts' in locals() else {}\n",
        "}\n",
        "\n",
        "print(f\"\\nüíæ Data prepared for phases 4-7:\")\n",
        "print(f\"   ‚Ä¢ {len(processed_data['sample_features'])} samples with extracted features\")\n",
        "print(f\"   ‚Ä¢ {len(processed_data['feature_columns'])} feature types identified\")\n",
        "print(f\"   ‚Ä¢ Vegetation analysis pipeline established\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"üåø VEGETATION MONITORING PROJECT - PHASES 1-3 COMPLETE! üåø\")\n",
        "print(\"=\"*60)"
      ]
    }
  ]
}