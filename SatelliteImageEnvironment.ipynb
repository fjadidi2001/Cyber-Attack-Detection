{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6UD3npCBNF7kD6XLobzcp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Cyber-Attack-Detection/blob/main/SatelliteImageEnvironment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```markdown\n",
        "# Vegetation Monitoring Workflow for Remote Sensing Satellite Images\n",
        "\n",
        "## Dataset Adaptation\n",
        "**Dataset**: `umeradnaan/remote-sensing-satellite-images` from Kaggle\n",
        "- **Structure**: Directory-based organization (likely class folders)\n",
        "- **Content**: Satellite imagery with land cover classes\n",
        "- **Key Changes**:\n",
        "  - No captions → Focus on class labels from directory structure\n",
        "  - Requires different loading approach\n",
        "  - Likely contains multiple land cover classes beyond vegetation\n",
        "\n",
        "## Revised Technical Workflow\n",
        "\n",
        "### Phase 1: Dataset Setup & Exploration\n",
        "```python\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset from directory\n",
        "def load_dataset(path):\n",
        "    classes = os.listdir(path)\n",
        "    images = []\n",
        "    labels = []\n",
        "    \n",
        "    for class_idx, class_name in enumerate(classes):\n",
        "        class_path = os.path.join(path, class_name)\n",
        "        for img_file in os.listdir(class_path):\n",
        "            if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "                images.append(img_path)\n",
        "                labels.append(class_idx)\n",
        "                \n",
        "    return images, labels, classes\n",
        "\n",
        "# Path from Kaggle download\n",
        "path = kagglehub.dataset_download(\"umeradnaan/remote-sensing-satellite-images\")\n",
        "image_paths, labels, class_names = load_dataset(path)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    image_paths, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "```\n",
        "\n",
        "### Phase 2: Vegetation-Focused Preprocessing\n",
        "**Key Adjustments**:\n",
        "1. **Standardize image sizes** (critical for satellite imagery)\n",
        "2. **Atmospheric correction** (simplified)\n",
        "3. **Shadow reduction** (common in satellite images)\n",
        "\n",
        "```python\n",
        "def preprocess_image(img_path, target_size=(256, 256)):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, target_size)\n",
        "    \n",
        "    # Simplified atmospheric correction\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    l = clahe.apply(l)\n",
        "    lab = cv2.merge((l,a,b))\n",
        "    img = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "    \n",
        "    # Shadow reduction\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])\n",
        "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "```\n",
        "\n",
        "### Phase 3: Vegetation Feature Extraction\n",
        "**Enhanced Techniques**:\n",
        "1. **Advanced Vegetation Indices**:\n",
        "   ```python\n",
        "   def calculate_vegetation_indices(rgb):\n",
        "       r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
        "       with np.errstate(divide='ignore', invalid='ignore'):\n",
        "           # Modified Visible Vegetation Index (MVVI)\n",
        "           mvvi = (g - 1.3*r) / (g + r - b)\n",
        "           mvvi = np.nan_to_num(mvvi)\n",
        "           \n",
        "           # Triangular Greenness Index (TGI)\n",
        "           tgi = g - 0.39*r - 0.61*b\n",
        "       return mvvi, tgi\n",
        "   ```\n",
        "2. **Multiscale Texture Analysis**:\n",
        "   - GLCM at multiple distances (1,3,5 pixels)\n",
        "   - Rotation-invariant LBP\n",
        "\n",
        "### Phase 4: Vegetation Classification & Segmentation\n",
        "**Revised Approach**:\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Feature extraction pipeline\n",
        "def extract_features(images):\n",
        "    features = []\n",
        "    for img in images:\n",
        "        preprocessed = preprocess_image(img)\n",
        "        mvvi, tgi = calculate_vegetation_indices(preprocessed)\n",
        "        \n",
        "        # Color features\n",
        "        color_features = np.concatenate((\n",
        "            np.mean(preprocessed, axis=(0,1)),\n",
        "            np.std(preprocessed, axis=(0,1))\n",
        "        ))\n",
        "        \n",
        "        # Texture features (GLCM example)\n",
        "        gray = cv2.cvtColor(preprocessed, cv2.COLOR_RGB2GRAY)\n",
        "        glcm = graycomatrix(gray, distances=[1], angles=[0], symmetric=True, normed=True)\n",
        "        contrast = graycoprops(glcm, 'contrast')[0,0]\n",
        "        \n",
        "        features.append(np.hstack([color_features, mvvi.mean(), tgi.mean(), contrast]))\n",
        "    return np.array(features)\n",
        "\n",
        "# Train classifier\n",
        "train_features = extract_features(X_train)\n",
        "classifier = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
        ")\n",
        "classifier.fit(train_features, y_train)\n",
        "```\n",
        "\n",
        "### Phase 5: Vegetation Health Assessment\n",
        "**Key Metrics**:\n",
        "1. **Vegetation Vigor Index**:\n",
        "   ```python\n",
        "   def calculate_vigor(img):\n",
        "       _, tgi = calculate_vegetation_indices(img)\n",
        "       return np.percentile(tgi, 75)  # Use 75th percentile to ignore outliers\n",
        "   ```\n",
        "2. **Stress Detection**:\n",
        "   - Color clustering in CIELAB space\n",
        "   - Brown/Yellow pixel ratio\n",
        "\n",
        "### Phase 6: Temporal Analysis (If Multiple Timestamps)\n",
        "**Implementation Strategy**:\n",
        "1. Organize images by location ID\n",
        "2. Compute vegetation index time series\n",
        "3. Use change vector analysis:\n",
        "   ```python\n",
        "   def detect_change(img1, img2):\n",
        "       mvvi1, _ = calculate_vegetation_indices(img1)\n",
        "       mvvi2, _ = calculate_vegetation_indices(img2)\n",
        "       change = mvvi2 - mvvi1\n",
        "       return np.abs(change) > 0.2  # Empirical threshold\n",
        "   ```\n",
        "\n",
        "### Phase 7: Validation\n",
        "**New Approach**:\n",
        "```python\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Test evaluation\n",
        "test_features = extract_features(X_test)\n",
        "y_pred = classifier.predict(test_features)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "# Vegetation-specific evaluation\n",
        "vegetation_indices = [i for i, name in enumerate(class_names) if 'vegetation' in name.lower()]\n",
        "vegetation_mask = np.isin(y_test, vegetation_indices)\n",
        "print(\"Vegetation Classification Accuracy:\",\n",
        "      accuracy_score(np.array(y_test)[vegetation_mask],\n",
        "      np.array(y_pred)[vegetation_mask]))\n",
        "```\n",
        "\n",
        "## Technical Adjustments for Satellite Imagery\n",
        "\n",
        "1. **Optimal Feature Set**:\n",
        "```python\n",
        "FEATURE_SET = [\n",
        "    'mean_R', 'mean_G', 'mean_B',\n",
        "    'std_R', 'std_G', 'std_B',\n",
        "    'MVVI_mean', 'TGI_mean',\n",
        "    'GLCM_contrast', 'GLCM_dissimilarity',\n",
        "    'vegetation_cover_ratio'\n",
        "]\n",
        "```\n",
        "\n",
        "2. **Vegetation-Specific Processing**:\n",
        "```python\n",
        "def create_vegetation_mask(img):\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    # Green color range in HSV\n",
        "    lower_green = np.array([35, 40, 40])\n",
        "    upper_green = np.array([85, 255, 255])\n",
        "    return cv2.inRange(hsv, lower_green, upper_green)\n",
        "```\n",
        "\n",
        "3. **Performance Optimization**:\n",
        "- Implement image tiling for large satellite images\n",
        "- Use OpenCV UMat for GPU acceleration\n",
        "- Apply pyramid downsampling for initial exploration\n",
        "\n",
        "## Revised Implementation Stack\n",
        "\n",
        "```python\n",
        "# Core libraries\n",
        "import cv2          # OpenCV 4.x\n",
        "import numpy as np\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Parallel processing\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "```\n",
        "\n",
        "## Critical Success Factors\n",
        "\n",
        "1. **Class Mapping Strategy**:\n",
        "```python\n",
        "VEGETATION_CLASSES = {\n",
        "    'forest': ['evergreen_forest', 'deciduous_forest'],\n",
        "    'agriculture': ['crops', 'farmland'],\n",
        "    'grassland': ['meadow', 'pasture'],\n",
        "    'stressed': ['dried_vegetation', 'burnt_areas']\n",
        "}\n",
        "```\n",
        "\n",
        "2. **Validation Approach**:\n",
        "- Stratified sampling by land cover class\n",
        "- Visual validation with NDVI comparisons (if other data sources available)\n",
        "- Confusion matrix analysis per vegetation type\n",
        "\n",
        "3. **Performance Targets**:\n",
        "- >85% accuracy for vegetation vs non-vegetation\n",
        "- >75% F1-score for vegetation sub-types\n",
        "- <15% false positives in change detection\n",
        "\n",
        "## Execution Plan\n",
        "\n",
        "1. **Phase 1** (2 days): Dataset organization and exploratory analysis\n",
        "2. **Phase 2-3** (3 days): Feature engineering pipeline\n",
        "3. **Phase 4** (2 days): Classifier training and optimization\n",
        "4. **Phase 5-6** (3 days): Health assessment and temporal analysis\n",
        "5. **Phase 7** (2 days): Validation and reporting\n",
        "\n",
        "## Key Advantages of Revised Workflow\n",
        "1. Handles directory-based dataset organization\n",
        "2. Robust to atmospheric distortions in satellite imagery\n",
        "3. Implements satellite-specific vegetation indices\n",
        "4. Includes class imbalance handling\n",
        "5. Optimized for medium-resolution satellite data\n",
        "6. GPU acceleration support through OpenCV\n",
        "```\n",
        "\n",
        "This revised workflow:\n",
        "1. Adapts to the Kaggle dataset's directory structure\n",
        "2. Uses satellite-specific preprocessing techniques\n",
        "3. Implements robust vegetation indices for RGB imagery\n",
        "4. Includes class imbalance handling strategies\n",
        "5. Optimizes for medium-resolution satellite data\n",
        "6. Provides clear validation metrics\n",
        "7. Adds temporal analysis capabilities\n",
        "8. Includes GPU acceleration options\n",
        "\n",
        "The workflow maintains focus on classical computer vision while addressing the unique characteristics of satellite imagery and directory-based dataset organization."
      ],
      "metadata": {
        "id": "ZIfdUAI94vMn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7NLIG-D24YZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bcd7af3-9254-42d4-f9ac-3e379531c6b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/satellite-image-classification\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mahmoudreda55/satellite-image-classification\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"umeradnaan/remote-sensing-satellite-images\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "OU894M0hMgCM",
        "outputId": "40edc781-e901-48a2-a3a5-8f2d538d9aac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/umeradnaan/remote-sensing-satellite-images?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49.9M/49.9M [00:00<00:00, 158MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/umeradnaan/remote-sensing-satellite-images/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import kagglehub\n",
        "\n",
        "# --- Step 1: Dataset Download & Organization ---\n",
        "def download_and_organize_dataset():\n",
        "    print(\"Downloading dataset from Kaggle...\")\n",
        "    dataset_path = kagglehub.dataset_download(\"umeradnaan/remote-sensing-satellite-images\")\n",
        "    print(f\"Dataset downloaded to: {dataset_path}\")\n",
        "    return dataset_path\n",
        "\n",
        "# --- Step 2: Dataset Structure Analysis ---\n",
        "def analyze_dataset_structure(dataset_path):\n",
        "    print(\"\\nAnalyzing dataset structure...\")\n",
        "\n",
        "    # List all classes (subdirectories)\n",
        "    classes = sorted([d for d in os.listdir(dataset_path)\n",
        "                     if os.path.isdir(os.path.join(dataset_path, d))])\n",
        "\n",
        "    # Count images per class\n",
        "    class_counts = {}\n",
        "    class_image_paths = {}\n",
        "\n",
        "    for cls in classes:\n",
        "        class_dir = os.path.join(dataset_path, cls)\n",
        "        images = [f for f in os.listdir(class_dir)\n",
        "                 if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        class_counts[cls] = len(images)\n",
        "        class_image_paths[cls] = [os.path.join(class_dir, img) for img in images]\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"Total classes: {len(classes)}\")\n",
        "    print(f\"Total images: {sum(class_counts.values())}\")\n",
        "    print(\"\\nClass distribution:\")\n",
        "    for cls, count in class_counts.items():\n",
        "        print(f\"- {cls}: {count} images\")\n",
        "\n",
        "    return classes, class_counts, class_image_paths\n",
        "\n",
        "# --- Step 3: Image Characteristics Analysis ---\n",
        "def analyze_image_characteristics(class_image_paths):\n",
        "    print(\"\\nAnalyzing image characteristics...\")\n",
        "\n",
        "    # Initialize analysis variables\n",
        "    resolutions = []\n",
        "    channels = []\n",
        "    color_stats = []\n",
        "\n",
        "    # Analyze sample of images from each class (5 per class)\n",
        "    for cls, paths in class_image_paths.items():\n",
        "        sample_paths = paths[:5]  # First 5 images per class\n",
        "\n",
        "        for img_path in sample_paths:\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Record image properties\n",
        "            resolutions.append(img.shape[:2])\n",
        "            channels.append(img.shape[2] if len(img.shape) > 2 else 1)\n",
        "\n",
        "            # Calculate basic color stats\n",
        "            if len(img.shape) > 2:  # Color image\n",
        "                color_stats.append({\n",
        "                    'mean': np.mean(img, axis=(0, 1)),\n",
        "                    'std': np.std(img, axis=(0, 1)),\n",
        "                    'min': np.min(img, axis=(0, 1)),\n",
        "                    'max': np.max(img, axis=(0, 1))\n",
        "                })\n",
        "\n",
        "    # Calculate statistics\n",
        "    resolution_counter = Counter(resolutions)\n",
        "    channel_counter = Counter(channels)\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\nImage resolutions (height, width):\")\n",
        "    for res, count in resolution_counter.most_common():\n",
        "        print(f\"- {res}: {count} images\")\n",
        "\n",
        "    print(\"\\nNumber of channels:\")\n",
        "    for ch, count in channel_counter.most_common():\n",
        "        print(f\"- {ch} channels: {count} images\")\n",
        "\n",
        "    # Calculate average color stats\n",
        "    if color_stats:\n",
        "        avg_mean = np.mean([stat['mean'] for stat in color_stats], axis=0)\n",
        "        avg_std = np.mean([stat['std'] for stat in color_stats], axis=0)\n",
        "        print(\"\\nAverage color values (BGR order):\")\n",
        "        print(f\"- Mean: {avg_mean}\")\n",
        "        print(f\"- Standard deviation: {avg_std}\")\n",
        "\n",
        "    return resolutions, channels\n",
        "\n",
        "# --- Step 4: Visual Exploration ---\n",
        "def visualize_class_samples(class_image_paths, classes, num_samples=3):\n",
        "    print(\"\\nVisualizing class samples...\")\n",
        "\n",
        "    # Set up visualization grid\n",
        "    num_cols = num_samples\n",
        "    num_rows = len(classes)\n",
        "    plt.figure(figsize=(15, 5 * num_rows))\n",
        "\n",
        "    for row_idx, cls in enumerate(classes):\n",
        "        sample_paths = class_image_paths[cls][:num_samples]\n",
        "\n",
        "        for col_idx, img_path in enumerate(sample_paths):\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            # Convert BGR to RGB for matplotlib\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Create subplot\n",
        "            ax = plt.subplot(num_rows, num_cols, row_idx * num_cols + col_idx + 1)\n",
        "            plt.imshow(img_rgb)\n",
        "            plt.title(f\"{cls}\\n{img.shape[1]}x{img.shape[0]}\")\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('dataset_samples.jpg')\n",
        "    plt.show()\n",
        "\n",
        "# --- Step 5: Vegetation Class Identification ---\n",
        "def identify_vegetation_classes(classes):\n",
        "    print(\"\\nIdentifying vegetation-related classes...\")\n",
        "\n",
        "    vegetation_keywords = ['forest', 'vegetation', 'tree', 'crop', 'grass', 'field', 'farm']\n",
        "    vegetation_classes = []\n",
        "\n",
        "    for cls in classes:\n",
        "        if any(keyword in cls.lower() for keyword in vegetation_keywords):\n",
        "            vegetation_classes.append(cls)\n",
        "\n",
        "    print(f\"Identified {len(vegetation_classes)} vegetation-related classes:\")\n",
        "    for veg_cls in vegetation_classes:\n",
        "        print(f\"- {veg_cls}\")\n",
        "\n",
        "    return vegetation_classes\n",
        "\n",
        "# --- Step 6: Dataset Splitting ---\n",
        "def prepare_train_test_split(class_image_paths, test_size=0.2):\n",
        "    print(\"\\nPreparing train/test split...\")\n",
        "\n",
        "    all_paths = []\n",
        "    all_labels = []\n",
        "\n",
        "    # Prepare data for splitting\n",
        "    for cls, paths in class_image_paths.items():\n",
        "        all_paths.extend(paths)\n",
        "        all_labels.extend([cls] * len(paths))\n",
        "\n",
        "    # Split dataset\n",
        "    train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "        all_paths, all_labels, test_size=test_size, random_state=42, stratify=all_labels\n",
        "    )\n",
        "\n",
        "    # Create metadata DataFrames\n",
        "    train_df = pd.DataFrame({'path': train_paths, 'label': train_labels})\n",
        "    test_df = pd.DataFrame({'path': test_paths, 'label': test_labels})\n",
        "\n",
        "    print(f\"Training images: {len(train_df)}\")\n",
        "    print(f\"Testing images: {len(test_df)}\")\n",
        "\n",
        "    # Save metadata\n",
        "    train_df.to_csv('train_metadata.csv', index=False)\n",
        "    test_df.to_csv('test_metadata.csv', index=False)\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# --- Main Execution ---\n",
        "def main():\n",
        "    # Setup directory structure\n",
        "    os.makedirs('outputs/exploration', exist_ok=True)\n",
        "    os.makedirs('outputs/visualizations', exist_ok=True)\n",
        "\n",
        "    # 1. Download dataset\n",
        "    dataset_path = download_and_organize_dataset()\n",
        "\n",
        "    # 2. Analyze dataset structure\n",
        "    classes, class_counts, class_image_paths = analyze_dataset_structure(dataset_path)\n",
        "\n",
        "    # 3. Analyze image characteristics\n",
        "    resolutions, channels = analyze_image_characteristics(class_image_paths)\n",
        "\n",
        "    # 4. Visualize samples\n",
        "    visualize_class_samples(class_image_paths, classes)\n",
        "\n",
        "    # 5. Identify vegetation classes\n",
        "    vegetation_classes = identify_vegetation_classes(classes)\n",
        "\n",
        "    # 6. Prepare train/test split\n",
        "    train_df, test_df = prepare_train_test_split(class_image_paths)\n",
        "\n",
        "    print(\"\\nPhase 1 completed successfully!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "ve4mlP__NFQO",
        "outputId": "393c347c-2244-4924-a84a-efbe3cae76a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset from Kaggle...\n",
            "Dataset downloaded to: /kaggle/input/remote-sensing-satellite-images\n",
            "\n",
            "Analyzing dataset structure...\n",
            "Total classes: 1\n",
            "Total images: 0\n",
            "\n",
            "Class distribution:\n",
            "- Remote Sensing Data.v2i.yolov8: 0 images\n",
            "\n",
            "Analyzing image characteristics...\n",
            "\n",
            "Image resolutions (height, width):\n",
            "\n",
            "Number of channels:\n",
            "\n",
            "Visualizing class samples...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Identifying vegetation-related classes...\n",
            "Identified 0 vegetation-related classes:\n",
            "\n",
            "Preparing train/test split...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3894860509>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-3894860509>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;31m# 6. Prepare train/test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_train_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_image_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPhase 1 completed successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-3894860509>\u001b[0m in \u001b[0;36mprepare_train_test_split\u001b[0;34m(class_image_paths, test_size)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;31m# Split dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     train_paths, test_paths, train_labels, test_labels = train_test_split(\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mall_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2851\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2852\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2481\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2482\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2483\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ]
    }
  ]
}