{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSepGQxKFQA4M8xUUk0cuo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Cyber-Attack-Detection/blob/main/SatelliteImageEnvironment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "```markdown\n",
        "# Vegetation Monitoring Workflow for Remote Sensing Satellite Images\n",
        "\n",
        "## Dataset Adaptation\n",
        "**New Dataset**: `umeradnaan/remote-sensing-satellite-images` from Kaggle\n",
        "- **Structure**: Directory-based organization (likely class folders)\n",
        "- **Content**: Satellite imagery with land cover classes\n",
        "- **Key Changes**:\n",
        "  - No captions â†’ Focus on class labels from directory structure\n",
        "  - Requires different loading approach\n",
        "  - Likely contains multiple land cover classes beyond vegetation\n",
        "\n",
        "## Revised Technical Workflow\n",
        "\n",
        "### Phase 1: Dataset Setup & Exploration\n",
        "```python\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset from directory\n",
        "def load_dataset(path):\n",
        "    classes = os.listdir(path)\n",
        "    images = []\n",
        "    labels = []\n",
        "    \n",
        "    for class_idx, class_name in enumerate(classes):\n",
        "        class_path = os.path.join(path, class_name)\n",
        "        for img_file in os.listdir(class_path):\n",
        "            if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "                images.append(img_path)\n",
        "                labels.append(class_idx)\n",
        "                \n",
        "    return images, labels, classes\n",
        "\n",
        "# Path from Kaggle download\n",
        "path = kagglehub.dataset_download(\"umeradnaan/remote-sensing-satellite-images\")\n",
        "image_paths, labels, class_names = load_dataset(path)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    image_paths, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "```\n",
        "\n",
        "### Phase 2: Vegetation-Focused Preprocessing\n",
        "**Key Adjustments**:\n",
        "1. **Standardize image sizes** (critical for satellite imagery)\n",
        "2. **Atmospheric correction** (simplified)\n",
        "3. **Shadow reduction** (common in satellite images)\n",
        "\n",
        "```python\n",
        "def preprocess_image(img_path, target_size=(256, 256)):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, target_size)\n",
        "    \n",
        "    # Simplified atmospheric correction\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    l = clahe.apply(l)\n",
        "    lab = cv2.merge((l,a,b))\n",
        "    img = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "    \n",
        "    # Shadow reduction\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])\n",
        "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "```\n",
        "\n",
        "### Phase 3: Vegetation Feature Extraction\n",
        "**Enhanced Techniques**:\n",
        "1. **Advanced Vegetation Indices**:\n",
        "   ```python\n",
        "   def calculate_vegetation_indices(rgb):\n",
        "       r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2]\n",
        "       with np.errstate(divide='ignore', invalid='ignore'):\n",
        "           # Modified Visible Vegetation Index (MVVI)\n",
        "           mvvi = (g - 1.3*r) / (g + r - b)\n",
        "           mvvi = np.nan_to_num(mvvi)\n",
        "           \n",
        "           # Triangular Greenness Index (TGI)\n",
        "           tgi = g - 0.39*r - 0.61*b\n",
        "       return mvvi, tgi\n",
        "   ```\n",
        "2. **Multiscale Texture Analysis**:\n",
        "   - GLCM at multiple distances (1,3,5 pixels)\n",
        "   - Rotation-invariant LBP\n",
        "\n",
        "### Phase 4: Vegetation Classification & Segmentation\n",
        "**Revised Approach**:\n",
        "```python\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Feature extraction pipeline\n",
        "def extract_features(images):\n",
        "    features = []\n",
        "    for img in images:\n",
        "        preprocessed = preprocess_image(img)\n",
        "        mvvi, tgi = calculate_vegetation_indices(preprocessed)\n",
        "        \n",
        "        # Color features\n",
        "        color_features = np.concatenate((\n",
        "            np.mean(preprocessed, axis=(0,1)),\n",
        "            np.std(preprocessed, axis=(0,1))\n",
        "        ))\n",
        "        \n",
        "        # Texture features (GLCM example)\n",
        "        gray = cv2.cvtColor(preprocessed, cv2.COLOR_RGB2GRAY)\n",
        "        glcm = graycomatrix(gray, distances=[1], angles=[0], symmetric=True, normed=True)\n",
        "        contrast = graycoprops(glcm, 'contrast')[0,0]\n",
        "        \n",
        "        features.append(np.hstack([color_features, mvvi.mean(), tgi.mean(), contrast]))\n",
        "    return np.array(features)\n",
        "\n",
        "# Train classifier\n",
        "train_features = extract_features(X_train)\n",
        "classifier = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
        ")\n",
        "classifier.fit(train_features, y_train)\n",
        "```\n",
        "\n",
        "### Phase 5: Vegetation Health Assessment\n",
        "**Key Metrics**:\n",
        "1. **Vegetation Vigor Index**:\n",
        "   ```python\n",
        "   def calculate_vigor(img):\n",
        "       _, tgi = calculate_vegetation_indices(img)\n",
        "       return np.percentile(tgi, 75)  # Use 75th percentile to ignore outliers\n",
        "   ```\n",
        "2. **Stress Detection**:\n",
        "   - Color clustering in CIELAB space\n",
        "   - Brown/Yellow pixel ratio\n",
        "\n",
        "### Phase 6: Temporal Analysis (If Multiple Timestamps)\n",
        "**Implementation Strategy**:\n",
        "1. Organize images by location ID\n",
        "2. Compute vegetation index time series\n",
        "3. Use change vector analysis:\n",
        "   ```python\n",
        "   def detect_change(img1, img2):\n",
        "       mvvi1, _ = calculate_vegetation_indices(img1)\n",
        "       mvvi2, _ = calculate_vegetation_indices(img2)\n",
        "       change = mvvi2 - mvvi1\n",
        "       return np.abs(change) > 0.2  # Empirical threshold\n",
        "   ```\n",
        "\n",
        "### Phase 7: Validation\n",
        "**New Approach**:\n",
        "```python\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Test evaluation\n",
        "test_features = extract_features(X_test)\n",
        "y_pred = classifier.predict(test_features)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "# Vegetation-specific evaluation\n",
        "vegetation_indices = [i for i, name in enumerate(class_names) if 'vegetation' in name.lower()]\n",
        "vegetation_mask = np.isin(y_test, vegetation_indices)\n",
        "print(\"Vegetation Classification Accuracy:\",\n",
        "      accuracy_score(np.array(y_test)[vegetation_mask],\n",
        "      np.array(y_pred)[vegetation_mask]))\n",
        "```\n",
        "\n",
        "## Technical Adjustments for Satellite Imagery\n",
        "\n",
        "1. **Optimal Feature Set**:\n",
        "```python\n",
        "FEATURE_SET = [\n",
        "    'mean_R', 'mean_G', 'mean_B',\n",
        "    'std_R', 'std_G', 'std_B',\n",
        "    'MVVI_mean', 'TGI_mean',\n",
        "    'GLCM_contrast', 'GLCM_dissimilarity',\n",
        "    'vegetation_cover_ratio'\n",
        "]\n",
        "```\n",
        "\n",
        "2. **Vegetation-Specific Processing**:\n",
        "```python\n",
        "def create_vegetation_mask(img):\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "    # Green color range in HSV\n",
        "    lower_green = np.array([35, 40, 40])\n",
        "    upper_green = np.array([85, 255, 255])\n",
        "    return cv2.inRange(hsv, lower_green, upper_green)\n",
        "```\n",
        "\n",
        "3. **Performance Optimization**:\n",
        "- Implement image tiling for large satellite images\n",
        "- Use OpenCV UMat for GPU acceleration\n",
        "- Apply pyramid downsampling for initial exploration\n",
        "\n",
        "## Revised Implementation Stack\n",
        "\n",
        "```python\n",
        "# Core libraries\n",
        "import cv2          # OpenCV 4.x\n",
        "import numpy as np\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Parallel processing\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "```\n",
        "\n",
        "## Critical Success Factors\n",
        "\n",
        "1. **Class Mapping Strategy**:\n",
        "```python\n",
        "VEGETATION_CLASSES = {\n",
        "    'forest': ['evergreen_forest', 'deciduous_forest'],\n",
        "    'agriculture': ['crops', 'farmland'],\n",
        "    'grassland': ['meadow', 'pasture'],\n",
        "    'stressed': ['dried_vegetation', 'burnt_areas']\n",
        "}\n",
        "```\n",
        "\n",
        "2. **Validation Approach**:\n",
        "- Stratified sampling by land cover class\n",
        "- Visual validation with NDVI comparisons (if other data sources available)\n",
        "- Confusion matrix analysis per vegetation type\n",
        "\n",
        "3. **Performance Targets**:\n",
        "- >85% accuracy for vegetation vs non-vegetation\n",
        "- >75% F1-score for vegetation sub-types\n",
        "- <15% false positives in change detection\n",
        "\n",
        "## Execution Plan\n",
        "\n",
        "1. **Phase 1** (2 days): Dataset organization and exploratory analysis\n",
        "2. **Phase 2-3** (3 days): Feature engineering pipeline\n",
        "3. **Phase 4** (2 days): Classifier training and optimization\n",
        "4. **Phase 5-6** (3 days): Health assessment and temporal analysis\n",
        "5. **Phase 7** (2 days): Validation and reporting\n",
        "\n",
        "## Key Advantages of Revised Workflow\n",
        "1. Handles directory-based dataset organization\n",
        "2. Robust to atmospheric distortions in satellite imagery\n",
        "3. Implements satellite-specific vegetation indices\n",
        "4. Includes class imbalance handling\n",
        "5. Optimized for medium-resolution satellite data\n",
        "6. GPU acceleration support through OpenCV\n",
        "```\n",
        "\n",
        "This revised workflow:\n",
        "1. Adapts to the Kaggle dataset's directory structure\n",
        "2. Uses satellite-specific preprocessing techniques\n",
        "3. Implements robust vegetation indices for RGB imagery\n",
        "4. Includes class imbalance handling strategies\n",
        "5. Optimizes for medium-resolution satellite data\n",
        "6. Provides clear validation metrics\n",
        "7. Adds temporal analysis capabilities\n",
        "8. Includes GPU acceleration options\n",
        "\n",
        "The workflow maintains focus on classical computer vision while addressing the unique characteristics of satellite imagery and directory-based dataset organization."
      ],
      "metadata": {
        "id": "ZIfdUAI94vMn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7NLIG-D24YZ0",
        "outputId": "1bcd7af3-9254-42d4-f9ac-3e379531c6b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/satellite-image-classification\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"mahmoudreda55/satellite-image-classification\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    }
  ]
}